{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#doing this manually because I hate myself, but not enough to automate it\n",
    "#[directory, filename, fitJSON for t0]\n",
    "filePathsOrderedWavScan = []\n",
    "#STD\n",
    "filePathsOrderedWavScan.append([r\"C:\\Users\\M\\Documents\\phdmatlab\\sqib-pmma-probe-wavelength\\UV_Setup\\new_parallel_pol_pump653nm\\STD-680\", r\"saturation_2024-01-16_14-09.mat\",  r\"TAfitPump653Probe680_DecayCorrected.JSON\", r\"SummaryPump653Probe680.JSON\"])\n",
    "filePathsOrderedWavScan.append([r\"C:\\Users\\M\\Documents\\phdmatlab\\sqib-pmma-probe-wavelength\\UV_Setup\\new_parallel_pol_pump653nm\\STD-520\", r\"saturation_2024-01-16_15-21.mat\",  r\"TAfitPump653Probe520_DecayCorrected.JSON\", r\"SummaryPump653Probe520.JSON\"])\n",
    "filePathsOrderedWavScan.append([r\"C:\\Users\\M\\Documents\\phdmatlab\\sqib-pmma-probe-wavelength\\UV_Setup\\new_parallel_pol_pump653nm\\STD-502\", r\"saturation_2024-01-16_14-51.mat\",  r\"TAfitPump653Probe502_DecayCorrected.JSON\", r\"SummaryPump653Probe502.JSON\"])\n",
    "filePathsOrderedWavScan.append([r\"C:\\Users\\M\\Documents\\phdmatlab\\sqib-pmma-probe-wavelength\\UV_Setup\\new_parallel_pol_pump653nm\\STD-493\", r\"saturation_2024-01-19_14-24.mat\",  r\"TAfitPump653Probe493_DecayCorrected.JSON\", r\"SummaryPump653Probe493Caution.JSON\"])\n",
    "#SHG\n",
    "filePathsOrderedWavScan.append([r\"C:\\Users\\M\\Documents\\phdmatlab\\sqib-pmma-probe-wavelength\\UV_Setup\\new_parallel_pol_pump653nm\\SHG-468\", r\"saturation_2024-01-16_18-38.mat\",  r\"TAfitPump653Probe468_DecayCorrected.JSON\", r\"SummaryPump653Probe468.JSON\"])\n",
    "filePathsOrderedWavScan.append([r\"C:\\Users\\M\\Documents\\phdmatlab\\sqib-pmma-probe-wavelength\\UV_Setup\\new_parallel_pol_pump653nm\\SHG-460\", r\"saturation_2024-01-18_17-34.mat\",  r\"TAfitPump653Probe460_DecayCorrected.JSON\", r\"SummaryPump653Probe460Caution.JSON\"])\n",
    "filePathsOrderedWavScan.append([r\"C:\\Users\\M\\Documents\\phdmatlab\\sqib-pmma-probe-wavelength\\UV_Setup\\new_parallel_pol_pump653nm\\SHG-450\", r\"saturation_2024-01-18_11-28.mat\",  r\"TAfitPump653Probe450_DecayCorrected.JSON\", r\"SummaryPump653Probe450.JSON\"])\n",
    "filePathsOrderedWavScan.append([r\"C:\\Users\\M\\Documents\\phdmatlab\\sqib-pmma-probe-wavelength\\UV_Setup\\new_parallel_pol_pump653nm\\SHG-440\", r\"saturation_2024-01-16_19-07.mat\",  r\"TAfitPump653Probe440_DecayCorrected.JSON\", r\"SummaryPump653Probe440.JSON\"])\n",
    "filePathsOrderedWavScan.append([r\"C:\\Users\\M\\Documents\\phdmatlab\\sqib-pmma-probe-wavelength\\UV_Setup\\new_parallel_pol_pump653nm\\SHG-430\", r\"saturation_2024-01-18_10-52.mat\",  r\"TAfitPump653Probe430_DecayCorrected.JSON\", r\"SummaryPump653Probe430.JSON\"])\n",
    "filePathsOrderedWavScan.append([r\"C:\\Users\\M\\Documents\\phdmatlab\\sqib-pmma-probe-wavelength\\UV_Setup\\new_parallel_pol_pump653nm\\SHG-420\", r\"saturation_2024-01-17_14-46.mat\",  r\"TAfitPump653Probe420_DecayCorrected.JSON\", r\"SummaryPump653Probe420.JSON\"])\n",
    "filePathsOrderedWavScan.append([r\"C:\\Users\\M\\Documents\\phdmatlab\\sqib-pmma-probe-wavelength\\UV_Setup\\new_parallel_pol_pump653nm\\SHG-410\", r\"saturation_2024-01-19_13-41.mat\",  r\"TAfitPump653Probe410_DecayCorrected.JSON\", r\"SummaryPump653Probe410Caution.JSON\"])\n",
    "filePathsOrderedWavScan.append([r\"C:\\Users\\M\\Documents\\phdmatlab\\sqib-pmma-probe-wavelength\\UV_Setup\\new_parallel_pol_pump653nm\\SHG-400\", r\"saturation_2024-01-17_15-26.mat\",  r\"TAfitPump653Probe400_DecayCorrected.JSON\", r\"SummaryPump653Probe400.JSON\"])\n",
    "filePathsOrderedWavScan.append([r\"C:\\Users\\M\\Documents\\phdmatlab\\sqib-pmma-probe-wavelength\\UV_Setup\\new_parallel_pol_pump653nm\\SHG-390\", r\"saturation_2024-01-18_12-03.mat\",  r\"TAfitPump653Probe390_DecayCorrected.JSON\", r\"SummaryPump653Probe390.JSON\"])\n",
    "filePathsOrderedWavScan.append([r\"C:\\Users\\M\\Documents\\phdmatlab\\sqib-pmma-probe-wavelength\\UV_Setup\\new_parallel_pol_pump653nm\\SHG-380\", r\"saturation_2024-01-17_16-31.mat\",  r\"TAfitPump653Probe380_2_DecayCorrected.JSON\", r\"SummaryPump653Probe380_2.JSON\"])\n",
    "filePathsOrderedWavScan.append([r\"C:\\Users\\M\\Documents\\phdmatlab\\sqib-pmma-probe-wavelength\\UV_Setup\\new_parallel_pol_pump653nm\\SHG-370\", r\"saturation_2024-01-17_17-11.mat\",  r\"TAfitPump653Probe370_DecayCorrected.JSON\", r\"SummaryPump653Probe370.JSON\"])\n",
    "filePathsOrderedWavScan.append([r\"C:\\Users\\M\\Documents\\phdmatlab\\sqib-pmma-probe-wavelength\\UV_Setup\\new_parallel_pol_pump653nm\\SHG-360\", r\"saturation_2024-01-18_15-50.mat\",  r\"TAfitPump653Probe360_DecayCorrected.JSON\", r\"SummaryPump653Probe360_2.JSON\"])\n",
    "filePathsOrderedWavScan.append([r\"C:\\Users\\M\\Documents\\phdmatlab\\sqib-pmma-probe-wavelength\\UV_Setup\\new_parallel_pol_pump653nm\\SHG-350\", r\"saturation_2024-01-18_16-39.mat\",  r\"TAfitPump653Probe350_DecayCorrected.JSON\", r\"SummaryPump653Probe350.JSON\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "from scipy import constants as const\n",
    "import plotHelperLatex\n",
    "plotHelperLatex.setMatplotSettings()\n",
    "#plt.rcParams['text.usetex'] = True\n",
    "\n",
    "#Sellmeier equation\n",
    "def n_squared(lamb, coeffs):\n",
    "    '''lamb in µm'''\n",
    "    n2 = 1\n",
    "    lsquare = lamb**2\n",
    "    for index in range(3):\n",
    "        n2 = n2 + coeffs[index, 0]*lsquare/(lsquare-coeffs[index, 1]**2)\n",
    "    return n2\n",
    "\n",
    "#Lensmaker equation\n",
    "def lensmaker(n, R1, R2, d=0):\n",
    "    '''Returns 1/focal length'''\n",
    "    f_inv = (n-1)*(1/R1 - 1/R2 + (n-1)*d/(n*R1*R2))\n",
    "    return f_inv\n",
    "\n",
    "\n",
    "def wavToEnergy(lamb):\n",
    "    #Energy in eV, lamb in nm\n",
    "    return const.h*const.c/lamb*1e9/const.elementary_charge\n",
    "\n",
    "def energyToWav(E):\n",
    "    #Energy in eV, lamb in nm\n",
    "    return const.h*const.c/E*1e9/const.elementary_charge\n",
    "\n",
    "\n",
    "\n",
    "#https://refractiveindex.info/?shelf=glass&book=fused_silica&page=Malitson\n",
    "#Maltison 1965 UV fused silica: 0.21 µm - 3.71 µm\n",
    "coeffsUVFS = np.array([[0.6961663, 0.0684043], [0.4079426, 0.1162414], [0.8974794, 9.896161]])\n",
    "\n",
    "#Energy range is 1.3 eV to 5 eV in .1 eV steps\n",
    "energies = np.linspace(1.3, 5, 37)*const.elementary_charge\n",
    "wavs = const.h*const.c/energies\n",
    "\n",
    "\n",
    "fig1, axs1 = plt.subplots(1,1, layout='constrained', figsize = plotHelperLatex.figSizer(1, 2.2), dpi = 288)\n",
    "#fig2, axs2 = plt.subplots(1,1, layout='constrained', figsize = (6,4), dpi=200)\n",
    "#µm for sellmeier\n",
    "n_wav = np.sqrt(n_squared(wavs*1e6, coeffsUVFS))\n",
    "axs1.plot(wavs*1e9, n_wav)\n",
    "axs1.set_ylabel('n / 1')\n",
    "axs1.set_xlabel(r'$\\lambda$ / nm')\n",
    "axs1.set_xticks(np.arange(250, 951, 100))\n",
    "secax0 = axs1.secondary_xaxis('top', functions=(wavToEnergy, energyToWav))\n",
    "secax0.set_xticks([1.5, 2, 3, 4, 5])\n",
    "secax0.set_xlabel(\"E / eV\")\n",
    "\n",
    "#second part with focal distance\n",
    "R1 = 59.5\n",
    "yaxisNtoF = lambda n_in: -1/lensmaker(n_in, np.inf, R1)\n",
    "#only for the particular case of plano conves\n",
    "yaxisFtoN = lambda f_in: (1+R1/f_in)\n",
    "\n",
    "print(yaxisNtoF(yaxisFtoN(100)))\n",
    "focal_distance = -lensmaker(n_wav, np.inf, R1)\n",
    "focal_distance = 1/focal_distance\n",
    "#axs1.plot(wavs*1e9, yaxisFtoN(focal_distance), 'r')\n",
    "#axs1.set_ylabel('f / mm')\n",
    "#axs1.set_xlabel(r'$\\lambda$ / nm')\n",
    "#axs1.set_xticks(np.arange(250, 951, 100))\n",
    "\n",
    "\n",
    "\n",
    "secax1 = axs1.secondary_yaxis('right', functions=(yaxisNtoF, yaxisFtoN))\n",
    "#secax1.set_xticks([1.5, 2, 3, 4, 5])\n",
    "secax1.set_ylabel('f / mm')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import plotHelperLatex\n",
    "plotHelperLatex.setMatplotSettings()\n",
    "\n",
    "#taken from edmund optics: Laser Optics and Resource Guide Section 2: Gaussian Beam Propagation\n",
    "\n",
    "w_c = lambda w0, lamb, z: w0*np.sqrt(1+(lamb*z/(np.pi*w0**2))**2)\n",
    "w0_c = lambda lamb, theta: lamb/np.pi/theta\n",
    "zr_c = lambda lamb, w0: np.pi*w0**2/lamb\n",
    "\n",
    "#collimated beam through lens with focal distance f\n",
    "#taken from angular aperture\n",
    "theta_c = lambda D, f: np.arctan(D/(2*f))\n",
    "\n",
    "\n",
    "\n",
    "wav = 653e-9 # nm\n",
    "#https://refractiveindex.info/?shelf=glass&book=fused_silica&page=Malitson\n",
    "#Maltison 1965 UV fused silica: 0.21 µm - 3.71 µm\n",
    "coeffsUVFS = np.array([[0.6961663, 0.0684043], [0.4079426, 0.1162414], [0.8974794, 9.896161]])\n",
    "n = np.sqrt(n_squared(wav*1e6,coeffsUVFS))\n",
    "f = 1/lensmaker(n, 59.4, np.inf)*1e-3\n",
    "\n",
    "diameters = np.array([1, 2, 3, 4])*1e-3 # mm\n",
    "thet = theta_c(diameters, f)\n",
    "w0 = w0_c(wav, thet)\n",
    "#print(w0*2)\n",
    "\n",
    "zr = zr_c(wav, w0[1])\n",
    "\n",
    "z = np.linspace(-5e-4, zr/2, 200)\n",
    "\n",
    "\n",
    "#plt.tight_layout()\n",
    "\n",
    "fig1, axs1 = plt.subplots(1,1, layout='constrained', figsize = plotHelperLatex.figSizer(2,1.4), dpi=144)\n",
    "fig2, axs2 = plt.subplots(1,1, layout='constrained', figsize = plotHelperLatex.figSizer(1.6, 1.4), dpi=144)\n",
    "#fig.suptitle(\"653 nm beam waist\")\n",
    "labelz = z[0]\n",
    "for index in range(len(diameters)):\n",
    "    axs1.plot(z*1e3, w_c(w0[index], wav, z)*2e6, label=\"%.1f mm\" %(diameters[index]*1e3))\n",
    "    axs1.text(labelz*1e3-0.65, w_c(w0[index], wav, labelz)*2e6, s=\"%.1f mm\" %(diameters[index]*1e3), fontdict = {\"fontsize\": \"small\", \"va\": \"center\", \"color\": fig1.gca().lines[-1].get_color()})\n",
    "axs1.set_xlabel(\"z / mm\")\n",
    "axs1.set_ylabel(\"beam waist / µm\")\n",
    "axs1.set_xlim((-1.2, 2))\n",
    "axs1.yaxis.tick_right()\n",
    "axs1.yaxis.set_label_position('right')\n",
    "\n",
    "\n",
    "\n",
    "z = np.linspace(-2e-4, zr/4, 200)\n",
    "\n",
    "labelz = z[-1]\n",
    "for index in range(len(diameters)):\n",
    "    axs2.plot(z*1e3, 1/(w_c(w0[index], wav, z)/w0[index])**2, label=\"%.1f mm\" %(diameters[index]*1e3))\n",
    "    axs2.text(labelz*1e3+0.01, 1/(w_c(w0[index], wav, labelz)/w0[index])**2, s=\"%.1f mm\" %(diameters[index]*1e3), fontdict = {\"fontsize\": \"small\", \"va\": \"center\", \"color\": fig2.gca().lines[-1].get_color()})\n",
    "axs2.set_xlabel(\"z / mm\")\n",
    "axs2.set_ylabel(\"relative maximum intensity / a.u.\")\n",
    "axs2.set_xlim((-0.3,1.1))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import plotHelperLatex\n",
    "plotHelperLatex.setMatplotSettings()\n",
    "\n",
    "#taken from edmund optics: Laser Optics and Resource Guide Section 2: Gaussian Beam Propagation\n",
    "\n",
    "w_c = lambda w0, lamb, z: w0*np.sqrt(1+(lamb*z/(np.pi*w0**2))**2)\n",
    "w0_c = lambda lamb, theta: lamb/np.pi/theta\n",
    "zr_c = lambda lamb, w0: np.pi*w0**2/lamb\n",
    "\n",
    "#collimated beam through lens with focal distance f\n",
    "#taken from angular aperture\n",
    "theta_c = lambda D, f: np.arctan(D/(2*f))\n",
    "\n",
    "\n",
    "dia = 2.5e-3 # m\n",
    "wavs = np.array([250,300, 400, 500, 600, 700, 800, 900])*1e-9 #wavs in m\n",
    "n = np.sqrt(n_squared(wav*1e6,coeffsUVFS))\n",
    "f = 1/lensmaker(n, 59.4, np.inf)*1e-3\n",
    "thet = theta_c(dia, f)\n",
    "w0 = w0_c(wavs, thet)\n",
    "\n",
    "zr = np.max(zr_c(wavs, w0))\n",
    "\n",
    "z = np.linspace(-2e-4, zr/4, 200)\n",
    "zlabel = z[-1]\n",
    "plt.figure()\n",
    "fig1, axs1 = plt.subplots(1,1, layout='constrained', figsize = plotHelperLatex.figSizer(2,1.4), dpi=144)\n",
    "#plt.title(\"Beam waist vs wavelength behavior at 2 mm collimated waist\")\n",
    "for index in range(len(wavs)):\n",
    "    axs1.plot(z*1e3, w_c(w0[index], wavs[index], z)*2e6, label=\"%.1f nm\" %(wavs[index]*1e9))\n",
    "    axs1.text(zlabel*1e3+0.01, w_c(w0[index], wavs[index], zlabel)*2e6, s=\"%.0f nm\" %(wavs[index]*1e9), fontdict = {\"fontsize\": \"small\", \"va\": \"center\", \"color\": plt.gca().lines[-1].get_color()})\n",
    "axs1.set_xlabel(\"z / mm\")\n",
    "axs1.set_ylabel(\"beam waist / µm\")\n",
    "axs1.set_xlim((-0.2, 1.05))\n",
    "#plt.legend()\n",
    "\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overlap normalised by max pump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import plotHelperLatex\n",
    "plotHelperLatex.setMatplotSettings()\n",
    "\n",
    "def gaussian(x, sig = 1, mu = 0):\n",
    "    return 1/(np.sqrt(2*np.pi)*sig)*np.exp(-(x-mu)**2/(2*sig**2))\n",
    "\n",
    "def gaussProd(x, sig1, sig2, mu1, mu2):\n",
    "    mu_n = (mu1*sig2**2 + mu2*sig1**2)/(sig1**2 + sig2**2)\n",
    "    sig_n = sig1*sig2/np.sqrt(sig1**2 + sig2**2)\n",
    "    return 1/(np.sqrt(2*np.pi)*sig_n)*np.exp(-(x-mu_n)**2/(2*sig_n**2))\n",
    "\n",
    "def cFactor(sigPump, sig2, mu1, mu2):\n",
    "    return np.sqrt((sigPump**2 + sig2**2)/sigPump**2)*np.exp((mu1-mu2)**2/(2*(sigPump**2+sig2**2)))\n",
    "\n",
    "\n",
    "\n",
    "def plotVisGaussians(x, sig2, dmu, norm = True, ax=None, colors = [\"blue\", \"royalblue\"]):\n",
    "    if ax == None:\n",
    "        fig, ax = plt.subplots(1,1)\n",
    "    #probe\n",
    "    #ax.plot(x, gaussian(x, 1, -dmu/2), label = r\"probe: $\\sigma$ = 1; $\\mu = %.1f$\" %(-dmu/2))\n",
    "    #pump r\"pump: $\\sigma$ = %d; $\\mu = %.1f$\" %(sig2, dmu)\n",
    "    ax.plot(x, gaussian(x, sig2, dmu), label = r\"pump\", color = colors[0], linestyle=\"dotted\")\n",
    "    #overlap\n",
    "    if norm == True:\n",
    "        ax.plot(x, gaussProd(x, 1, sig2, -dmu, 0), \"r--\", label = r\"overlap\")\n",
    "    elif norm == False:\n",
    "        relativeGaussiantoProbe = gaussian(x,1,0)*gaussian(x, sig2, dmu)/max(gaussian(x, sig2, +dmu))\n",
    "        #plt.plot(x, relativeGaussiantoProbe, \"r--\", label = r\"overlap\")\n",
    "        ax.fill_between(x, relativeGaussiantoProbe, hatch='/', color=colors[1], facecolor=\"None\")\n",
    "    ax.legend()\n",
    "    ax.set_xlabel(r\"x / $\\sigma_{probe}$\")\n",
    "    ax.set_ylabel(r\"I / a.u.\")\n",
    "    ax.set_title(r\"$\\frac{\\sigma_{pump}}{\\sigma_{probe}} = %.1d$, $\\Delta\\mu$ = %.1f $\\sigma_{probe}$,  C = %.2f\" %(sig2,dmu, cFactor(sig2, 1, dmu,0)), pad=8)\n",
    "    #plt.show()\n",
    "    return ax\n",
    "\n",
    "\n",
    "x = np.linspace(-3, 3, 200)\n",
    "fig, axs = plt.subplots(3,1, figsize = plotHelperLatex.figSizer(1,1.4), dpi=288, sharex=True)\n",
    "for ver in range(3):\n",
    "    #plot probe first\n",
    "    axs[ver].plot(x, gaussian(x, 1, 0), label = r\"probe\", color=\"teal\")\n",
    "\n",
    "\n",
    "#case 1 µ1 = µ2, sig 1 >> sig 2\n",
    "#\n",
    "sig2 = 1 #times sig 1; sig2 is pump\n",
    "dmu = 1.5\n",
    "plotVisGaussians(x, sig2, dmu, False, ax= axs[1])\n",
    "\n",
    "sig2 = 1 #times sig 1; sig2 is pump\n",
    "dmu = 0\n",
    "plotVisGaussians(x, sig2, dmu, False, colors = [\"orangered\", \"orangered\"], ax=axs[0])\n",
    "\n",
    "sig2 = 5 #times sig 1; sig2 is pump\n",
    "dmu = 0\n",
    "plotVisGaussians(x, sig2, dmu, False, ax= axs[2], colors=[\"purple\", \"purple\"])\n",
    "fig.subplots_adjust(hspace=0)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import plotHelperLatex\n",
    "plotHelperLatex.setMatplotSettings()\n",
    "\n",
    "def gaussian(x, sig = 1, mu = 0):\n",
    "    return 1/(np.sqrt(2*np.pi)*sig)*np.exp(-(x-mu)**2/(2*sig**2))\n",
    "\n",
    "def gaussProd(x, sig1, sig2, mu1, mu2):\n",
    "    mu_n = (mu1*sig2**2 + mu2*sig1**2)/(sig1**2 + sig2**2)\n",
    "    sig_n = sig1*sig2/np.sqrt(sig1**2 + sig2**2)\n",
    "    return 1/(np.sqrt(2*np.pi)*sig_n)*np.exp(-(x-mu_n)**2/(2*sig_n**2))\n",
    "\n",
    "def cFactor(sigPump, sig2, mu1, mu2):\n",
    "    return np.sqrt((sigPump**2 + sig2**2)/sigPump**2)*np.exp((mu1-mu2)**2/(2*(sigPump**2+sig2**2)))\n",
    "\n",
    "\n",
    "\n",
    "def plotVisGaussians(x, sig2, dmu):\n",
    "    plt.figure()\n",
    "    #probe\n",
    "    plt.plot(x, gaussian(x, 1, -dmu/2), label = r\"probe: $\\sigma$ = 1; $\\mu = %.1f$\" %(-dmu/2))\n",
    "    #pump\n",
    "    plt.plot(x, gaussian(x, 2, +dmu/2), label = r\"pump: $\\sigma$ = %d; $\\mu = %.1f$\" %(sig2, dmu/2))\n",
    "    #overlap\n",
    "    plt.plot(x, gaussProd(x, 1, sig2, -dmu/2, dmu/2), \"r--\", label = r\"overlap\")\n",
    "    plt.legend()\n",
    "    plt.xlabel(r\"x / $\\sigma$\")\n",
    "    plt.ylabel(r\"I / a.u.\")\n",
    "    plt.title(r\"C = %.2e\" %(cFactor(sig2, 1, dmu,0)))\n",
    "    plt.show()\n",
    "\n",
    "def plotCompareGaussians(x, sigPump, dmu_vec):\n",
    "    fig = plt.figure()\n",
    "    #plot pump gaussian\n",
    "    plt.plot(x, gaussian(x, sigPump, 0))\n",
    "    for ind in range(len(dmu_vec)):\n",
    "        plt.plot(x, gaussian(x, 1, dmu_vec[ind]), label=\"C = %.3f\" %cFactor(sigPump, 1, 0, dmu_vec[ind]))\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    fig.clear()\n",
    "\n",
    "#case 1 µ1 = µ2, sig 1 >> sig 2\n",
    "#\n",
    "sig2 = 3 #times sig 1; sig2 is pump\n",
    "dmu = 0 \n",
    "\n",
    "x = np.linspace(-3, 3, 200)\n",
    "dmu = [0, 0.1, 0.3, 0.5]\n",
    "sigPump = 3\n",
    "plotCompareGaussians(x, sigPump, dmu*sigPump)\n",
    "sigPump = 2\n",
    "plotCompareGaussians(x, sigPump, dmu*sigPump)\n",
    "sigPump = 1\n",
    "plotCompareGaussians(x, sigPump, dmu*sigPump)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New binning with interpolation in test_binning_interpol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test binning of numerical correction factor\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import plotHelperLatex\n",
    "plotHelperLatex.setMatplotSettings()\n",
    "\n",
    "def gaussian(x, sig = 1, mu = 0):\n",
    "    return 1/(np.sqrt(2*np.pi)*sig)*np.exp(-(x-mu)**2/(2*sig**2))\n",
    "\n",
    "def cFactor(sigPump, sig2, mu1, mu2):\n",
    "    return np.sqrt((sigPump**2 + sig2**2)/sigPump**2)*np.exp((mu1-mu2)**2/(2*(sigPump**2+sig2**2)))\n",
    "\n",
    "def binMap(map, xBinning, yBinning=0):\n",
    "    '''N_binning means that N*N pixels are binned together\\n\n",
    "    only takes square z*z maps'''\n",
    "    if yBinning == 0:\n",
    "        yBinning = xBinning\n",
    "    xBins = int(np.shape(map)[0]//xBinning) #along one axis\n",
    "    yBins = int(np.shape(map)[1]//yBinning) #along one axis\n",
    "    outmap = map.reshape(xBins, xBinning, yBins, yBinning).sum(3).sum(1)\n",
    "    return outmap\n",
    "\n",
    "\n",
    "#using identical gaussians for this\n",
    "points_per_sig = 1024 #starting value 1000 points for 1 sig distance\n",
    "sig = 1 #does not matter since I do binning in steps of sig at first\n",
    "mu = 0\n",
    "###----analytical cFactor ----###\n",
    "cFactorAnalytic = cFactor(sig, sig, mu, mu)**2\n",
    "print(\"Analytic correction factor:\\n \" + str(cFactorAnalytic))\n",
    "###----numeric cFactor ----###\n",
    "nsig = 5 # how far I measure to the sides\n",
    "x_like = np.linspace(-nsig*sig,nsig*sig, 2*nsig*points_per_sig)\n",
    "Xvec, Yvec = np.array(np.meshgrid(x_like,x_like))\n",
    "\n",
    "\n",
    "gaussStd = gaussian(Xvec, sig, mu)*gaussian(Yvec, sig, mu)\n",
    "\n",
    "\n",
    "\n",
    "n_steps = 11\n",
    "binning_steps=np.zeros(n_steps, dtype=int)\n",
    "\n",
    "for i in range(n_steps):\n",
    "    binning_steps[i] = 2**i\n",
    "#print(binning_steps)\n",
    "\n",
    "#first without added noise\n",
    "print(\"Correction Factor numeric, no noise:\")\n",
    "noNoiseGaussCorrection = np.zeros(len(binning_steps))\n",
    "for ind in range(len(binning_steps)):\n",
    "    gaussBinned = binMap(gaussStd, binning_steps[ind])\n",
    "    #pump = np.ones(np.shape(gaussBinned))\n",
    "    pump = gaussBinned\n",
    "    probe = gaussBinned\n",
    "    denominator = np.sum(np.multiply(pump, probe)[:])\n",
    "    constantPumpIntensity = np.max(pump)\n",
    "    #print(constantPumpIntensity)\n",
    "    enumerator = np.sum(constantPumpIntensity*probe[:])\n",
    "    #this is missing various constant factors, since this is not using the gaussian shape, but is discretized\n",
    "    noNoiseGaussCorrection[ind] = enumerator/denominator\n",
    "    print(\"binning = 1/\"+str(binning_steps[ind])+\": \" + str(noNoiseGaussCorrection[ind]))\n",
    "\n",
    "plt.figure(dpi = 288, figsize=plotHelperLatex.figSizer(1,2))\n",
    "plt.plot(np.linspace(n_steps-1,0,n_steps), noNoiseGaussCorrection, label = \"no noise\")\n",
    "#with added noise\n",
    "Noiselevels = [0.05,0.1,0.2]\n",
    "NoiseGaussCorrection = np.zeros((len(Noiselevels), len(binning_steps)))\n",
    "for indexSNR, SNR in enumerate(Noiselevels):\n",
    "\n",
    "    gauss1 = gaussStd + (np.random.rand(np.shape(gaussStd)[0], np.shape(gaussStd)[1])-0.5)*np.max(gaussStd)*SNR\n",
    "    gauss2 = gaussStd + (np.random.rand(np.shape(gaussStd)[0], np.shape(gaussStd)[1])-0.5)*np.max(gaussStd)*SNR\n",
    "    \n",
    "    for ind in range(len(binning_steps)):\n",
    "        pump = binMap(gauss1, binning_steps[ind])\n",
    "        probe = binMap(gauss2, binning_steps[ind])\n",
    "        denominator = np.sum(np.multiply(pump, probe)[:])\n",
    "        constantPumpIntensity = np.max(pump)\n",
    "        enumerator = np.sum(constantPumpIntensity*probe[:])\n",
    "        #this is missing various constant factors, since this is not using the gaussian shape, but is discretized\n",
    "        NoiseGaussCorrection[indexSNR, ind] = enumerator/denominator\n",
    "    plt.plot(np.linspace(n_steps-1,0,n_steps), NoiseGaussCorrection[indexSNR], label = \"SNR = %.2f dB\" %(10*np.log10(1/SNR)), linestyle='dashed')\n",
    "\n",
    "\n",
    "\n",
    "plt.plot([0,n_steps-1], [2,2], label=\"analytical correction\", linestyle=\"dotted\", color = 'red')\n",
    "plt.xlabel(r\"$\\mathrm{log_2}$ of discrete point density per $\\sigma$ / 1\")\n",
    "plt.ylabel(\"correction factor / 1\")\n",
    "plt.ylim([1,2.5])\n",
    "plt.legend(loc=\"lower right\", fontsize = \"small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test binning of numerical correction factor\n",
    "#Testing how the offset actually behaves\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import plotHelperLatex\n",
    "plotHelperLatex.setMatplotSettings()\n",
    "\n",
    "def gaussian(x, sig = 1, mu = 0):\n",
    "    return 1/(np.sqrt(2*np.pi)*sig)*np.exp(-(x-mu)**2/(2*sig**2))\n",
    "\n",
    "def cFactor(sigPump, sig2, mu1, mu2):\n",
    "    return np.sqrt((sigPump**2 + sig2**2)/sigPump**2)*np.exp((mu1-mu2)**2/(2*(sigPump**2+sig2**2)))\n",
    "\n",
    "def binMap(map, xBinning, yBinning=0):\n",
    "    '''N_binning means that N*N pixels are binned together\\n\n",
    "    only takes square z*z maps'''\n",
    "    if yBinning == 0:\n",
    "        yBinning = xBinning\n",
    "    xBins = int(np.shape(map)[0]//xBinning) #along one axis\n",
    "    yBins = int(np.shape(map)[1]//yBinning) #along one axis\n",
    "    outmap = map.reshape(xBins, xBinning, yBins, yBinning).sum(3).sum(1)\n",
    "    return outmap\n",
    "\n",
    "\n",
    "#using identical gaussians for this\n",
    "points_per_sig = 1024 #starting value 1000 points for 1 sig distance\n",
    "sig = 1 #does not matter since I do binning in steps of sig at first\n",
    "dmu = 1\n",
    "###----analytical cFactor ----###\n",
    "#one sigma multiplicator\n",
    "sigPumpYModifier= 2\n",
    "sigPumpXModifier = 0.8\n",
    "cFactorAnalytic = cFactor(sigPumpXModifier*sig, sig, dmu/2, -dmu/2)*cFactor(sigPumpYModifier*sig, sig, dmu/2, -dmu/2)\n",
    "print(\"Analytic correction factor:\\n \" + str(cFactorAnalytic))\n",
    "###----numeric cFactor ----###\n",
    "nsig = 5 # how far I measure to the sides\n",
    "x_like = np.linspace(-nsig*sig,nsig*sig, 2*nsig*points_per_sig)\n",
    "Xvec, Yvec = np.array(np.meshgrid(x_like,x_like))\n",
    "\n",
    "\n",
    "n_steps = 11\n",
    "binning_steps=np.zeros(n_steps, dtype=int)\n",
    "for i in range(n_steps):\n",
    "    binning_steps[i] = 2**i\n",
    "\n",
    "d_offset = [0,0.1,0.2,0.5]\n",
    "GaussCorrection = np.zeros((len(d_offset),len(binning_steps)))\n",
    "for indOffset, offset in enumerate(d_offset):\n",
    "\n",
    "    pumpGauss = gaussian(Xvec, sigPumpXModifier*sig, +dmu/2+offset)*gaussian(Yvec, sigPumpYModifier*sig, +dmu/2)\n",
    "    probeGauss = gaussian(Xvec, sig, -dmu/2+offset)*gaussian(Yvec, sig, -dmu/2)\n",
    "\n",
    "\n",
    "    for ind in range(len(binning_steps)):\n",
    "        pump = binMap(pumpGauss, binning_steps[ind])\n",
    "        probe = binMap(probeGauss, binning_steps[ind])\n",
    "        denominator = np.sum(np.multiply(pump, probe)[:])\n",
    "        constantPumpIntensity = np.max(pump)\n",
    "        enumerator = np.sum(constantPumpIntensity*probe[:])\n",
    "        #this is missing various constant factors, since this is not using the gaussian shape, but is discretized\n",
    "        GaussCorrection[indOffset, ind] = enumerator/denominator\n",
    "\n",
    "\n",
    "plt.figure(dpi = 288, figsize=plotHelperLatex.figSizer(1,2))\n",
    "for i in range(len(d_offset)):\n",
    "    plt.plot(np.linspace(n_steps-1,0,n_steps), GaussCorrection[i], label = r\"$\\Delta x_\\mathrm{grid}$ = %.1f $\\sigma$\" %(d_offset[i]))\n",
    "plt.plot([0,n_steps-1], [cFactorAnalytic,cFactorAnalytic], label=\"analytical correction\", linestyle=\"dotted\", color = 'red')\n",
    "plt.xlabel(r\"$\\mathrm{log_2}$ of discrete point density per $\\sigma$ / 1\")\n",
    "plt.ylabel(\"correction factor / 1\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import constants as const\n",
    "import numpy as np\n",
    "import plotHelperLatex\n",
    "plotHelperLatex.setMatplotSettings()\n",
    "\n",
    "umPerPx = 6.949\n",
    "dumPerPx = 4E-2\n",
    "dRelUmPerPx = dumPerPx/umPerPx\n",
    "\n",
    "def wavToEnergy(lamb):\n",
    "    #Energy in eV, lamb in nm\n",
    "    return const.h*const.c/lamb*1e9/const.elementary_charge\n",
    "\n",
    "def energyToWav(E):\n",
    "    #Energy in eV, lamb in nm\n",
    "    return const.h*const.c/E*1e9/const.elementary_charge\n",
    "\n",
    "def paramDictatTime(param_dict, time_fs):\n",
    "    return param_dict['A1']*np.exp(-time_fs/param_dict['tau1']) + param_dict['A2']*np.exp(-time_fs/param_dict['tau2'])\n",
    "#import data from excel (terrible choice I know, but I want the visualisation and comparability)\n",
    "\n",
    "def ErrorCorrectionConvoluted(signal, correctionFactor, peakRadiance, dRelUmPerPx, dRelPower):\n",
    "    '''correctionfactor is already divided with peak radiance\\\\\n",
    "    dRelPower = dPower/Power'''\n",
    "    dPeakRadiance = dRelPower*peakRadiance + 2*peakRadiance*dRelUmPerPx\n",
    "    return abs(signal*correctionFactor/peakRadiance*dPeakRadiance)\n",
    "\n",
    "def ErrorCorrectionSimple(signal, correctionFactor, peakRadiance, dRelPower):\n",
    "    dPeakRadiance = dRelPower*peakRadiance\n",
    "    return abs(signal*correctionFactor/peakRadiance*dPeakRadiance)\n",
    "\n",
    "def fitPeaks(x_data, y_data, N_gaussians, centers = [], sigma = [], amplitudes = [], positionBounds = [], ampBounds = [], function = None):\n",
    "    from scipy.optimize import curve_fit\n",
    "    startParameters = np.ones(3*N_gaussians)\n",
    "    min_bounds = []\n",
    "    max_bounds = []\n",
    "    if len(centers) != N_gaussians:\n",
    "        centers = np.linspace(min(x_data), max(x_data),N_gaussians)\n",
    "    \n",
    "    if len(amplitudes) != N_gaussians:\n",
    "        amplitudes = max(np.abs(y_data))/N_gaussians*np.ones(N_gaussians)\n",
    "    if len(sigma) != N_gaussians:\n",
    "        sigma = np.ones(N_gaussians)*0.01\n",
    "\n",
    "    for i in range(N_gaussians):\n",
    "        startParameters[i*3+1] = sigma[i]\n",
    "        startParameters[i*3] = centers[i]\n",
    "        startParameters[i*3+2] = amplitudes[i]\n",
    "\n",
    "    for i in range(N_gaussians):\n",
    "        if len(positionBounds) == 0:\n",
    "            min_bounds.append(min(x_data))\n",
    "            max_bounds.append(max(x_data))\n",
    "        else:\n",
    "            min_bounds.append(positionBounds[i][0])\n",
    "            max_bounds.append(positionBounds[i][1])\n",
    "        min_bounds.append(0)\n",
    "        max_bounds.append(np.inf)\n",
    "        if len(ampBounds) == 0:\n",
    "            min_bounds.append(-np.inf)\n",
    "            max_bounds.append(np.inf)\n",
    "        else:\n",
    "            min_bounds.append(ampBounds[0])\n",
    "            max_bounds.append(ampBounds[1])\n",
    "    par_bounds = [tuple(min_bounds), tuple(max_bounds)]\n",
    "\n",
    "\n",
    "    popt, pcov = curve_fit(function, x_data, y_data, \n",
    "            p0 = startParameters, \n",
    "            bounds = par_bounds,\n",
    "            method=\"trf\")\n",
    "    return popt, pcov\n",
    "\n",
    "def multiGaussianAdditive(x_data, *parameters):\n",
    "    r'''parameters are parameters[number of gaussian, center/sig/amplitude]'''\n",
    "    y_out = np.zeros(np.shape(x_data))\n",
    "    for gaussInd in range(0,len(parameters),3):\n",
    "        y_out += parameters[gaussInd+2]*np.exp(-np.power(x_data-parameters[gaussInd+0], 2)/(2*np.power(parameters[gaussInd+1],2)))\n",
    "    return y_out\n",
    "\n",
    "def multiLorentzianAdditive(x_data, *parameters):\n",
    "    r'''parameters are parameters[number of gaussian, center/gamma/amplitude]'''\n",
    "    y_out = np.zeros(np.shape(x_data))\n",
    "    for cauchyInd in range(0,len(parameters),3):\n",
    "        #y_out += 1/(np.pi*parameters[cauchyInd+1]*(1+np.power((x_data-parameters[cauchyInd])/parameters[cauchyInd+1],2)))\n",
    "        #removing normalisation constant, want it to be 1 in center position\n",
    "        y_out += parameters[cauchyInd+2]/((1+np.power((x_data-parameters[cauchyInd])/parameters[cauchyInd+1],2)))\n",
    "    return y_out\n",
    "\n",
    "\n",
    "excel_path = r\"C:\\Users\\M\\Documents\\phdmatlab\\sqib-pmma-probe-wavelength\\UV_Setup\\new_parallel_pol_pump653nm\\CorrectedPump653ProbeWavelengthScan_UV-extended.xlsx\"\n",
    "SHG_wav_timescan = pd.read_excel(excel_path, sheet_name = \"2024WavelengthScanParameters\", skiprows=[0,1])\n",
    "SHG_main = pd.read_excel(excel_path, sheet_name='2024WavelengthScan', skiprows=[0,1])\n",
    "#print(SHG_main)\n",
    "#print(SHG_main.keys())\n",
    "\n",
    "\n",
    "wavelengths = SHG_main['Probe wavelength / nm']\n",
    "#simple correction without map\n",
    "dOD_SHG_main = SHG_main['cor_dOD / (mOD*m^2/W)']\n",
    "#correction with map\n",
    "dOD_SHG_mapCorr = SHG_main['hypothetical correction']\n",
    "dOD_map_reference = SHG_main['mapReference']\n",
    "dPumpPower = SHG_main['dRelPumpPower']\n",
    "peakRad = SHG_main['Pump power density / (W/m^2)']\n",
    "\n",
    "#map reference correction\n",
    "dOD_map_reference = abs(dOD_map_reference/np.mean(dOD_map_reference))\n",
    "\n",
    "scan_wavs = np.array(SHG_wav_timescan['Probe wavelength / nm'])\n",
    "scan_corrFactors = np.array(SHG_wav_timescan['Correction Factor / (W/m^2)^-1'])\n",
    "scan_params = {\n",
    "    'A1' : SHG_wav_timescan['A1'],\n",
    "    'A2' : SHG_wav_timescan['A2'],\n",
    "    'tau1' : SHG_wav_timescan['tau1'],\n",
    "    'tau2' : SHG_wav_timescan['tau2'],\n",
    "}\n",
    "\n",
    "scan_corrFactors[7] = np.nan\n",
    "#times = np.array([1e2, 1e4, 2e4, 4e4])\n",
    "#################NEW DUE TO 380 nm measurement being bad, only using one of them##############\n",
    "totalSignalTesting = dOD_map_reference*paramDictatTime(scan_params, 1e2)*scan_corrFactors\n",
    "times = np.array([1e2, 1e4, 4e4])\n",
    "\"\"\"\"\"\"\n",
    "bool_mask = np.invert(np.isnan(totalSignalTesting))\n",
    "\n",
    "yerrCalc = ErrorCorrectionSimple(dOD_map_reference*paramDictatTime(scan_params, 1e2), scan_corrFactors, peakRad, dPumpPower)[bool_mask]\n",
    "\n",
    "totalSignalTesting=totalSignalTesting[bool_mask]\n",
    "dOD_map_reference = dOD_map_reference[bool_mask]\n",
    "scan_corrFactors = scan_corrFactors[bool_mask]\n",
    "peakRad = peakRad[bool_mask]\n",
    "dPumpPower = dPumpPower[bool_mask]\n",
    "scan_wavs = scan_wavs[bool_mask]\n",
    "wavelengths = wavelengths[bool_mask]\n",
    "\n",
    "yerrCalc = np.reshape(yerrCalc, (-1))\n",
    "\"\"\"\"\"\"\n",
    "#print(ErrorCorrectionConvoluted(dOD_SHG_main, scan_corrFactors, peakRad, dRelUmPerPx, dPumpPower))\n",
    "fig, ax = plt.subplots(1,1, figsize=plotHelperLatex.figSizer(1,2), dpi = 288)\n",
    "colors = ['red', 'green', 'orange', 'royalblue']\n",
    "#plot 1e2 fs time errorbar\n",
    "#signalFit = [2.82, 0.14, 1e-3, 2.48, 0.09, 1.3e-3]\n",
    "Lorentz = True\n",
    "\n",
    "#signalFit, signalCov = fitPeaks(wavToEnergy(wavelengths[1:-2]), totalSignalTesting[1:-2],2, [2.82, 2.48], [0.1, 0.05],[1e-3, 1e-3])\n",
    "\n",
    "if Lorentz == True:\n",
    "    signalFit, signalCov = fitPeaks(wavToEnergy(wavelengths[1:-2]), totalSignalTesting[1:-2],3, [2.82, 2.48, 3.15], [0.1,0.05, 0.03], [4e-4, 4e-4, 1e-4], positionBounds=[[2.76, 2.83], [2.3, 2.7], [3.00,3.60]], ampBounds=[0,2e-3], function=multiLorentzianAdditive)\n",
    "    #signalFit, signalCov = fitPeaks(wavToEnergy(wavelengths[1:-2]), totalSignalTesting[1:-2],2, [2.82, 2.48], [0.1,0.05], [1e-3, 1e-3], function=multiLorentzianAdditive)\n",
    "else:\n",
    "    signalFit, signalCov = fitPeaks(wavToEnergy(wavelengths[1:-2]), totalSignalTesting[1:-2],3, [2.82, 2.48, 3.55], [0.1,0.05, 0.02], [1e-3, 1e-3, 2e-4], positionBounds=[[2.76, 2.83], [2.3, 2.7], [3.20,3.60]], function=multiGaussianAdditive)\n",
    "#plot gaussians\n",
    "print(signalFit)\n",
    "print(np.sqrt(np.diag(signalCov)))\n",
    "wav_range = np.linspace(350,550,500)\n",
    "if Lorentz == True:\n",
    "    ax.plot(wav_range, multiLorentzianAdditive(wavToEnergy(wav_range), *signalFit), label=r\"$\\sum$ fits\", color=\"m\", alpha=0.5,linestyle=\"-\")\n",
    "    for i in range(0,len(signalFit),3):\n",
    "        ax.plot(wav_range, multiLorentzianAdditive(wavToEnergy(wav_range), *signalFit[i:i+3]), label=\"fit \"+str(int(i/3)), alpha=0.5,linestyle=\"-\")\n",
    "else:\n",
    "    ax.plot(wav_range, multiGaussianAdditive(wavToEnergy(wav_range), *signalFit), label=\"sum gauss\")\n",
    "    for i in range(0,len(signalFit),3):\n",
    "        ax.plot(wav_range, multiGaussianAdditive(wavToEnergy(wav_range), *signalFit[i:i+3]), label=\"gauss fit \"+str(int(i/3)), linestyle=\"dashed\")\n",
    "\n",
    "\n",
    "ax.errorbar(wavelengths, totalSignalTesting, yerr = yerrCalc, ls = \"None\", capsize =2, ecolor=colors[0])\n",
    "\n",
    "'''\n",
    "ax.plot(wavelengths, dOD_SHG_main, 'ro', label='standard correction', ls = \"None\")\n",
    "ax.plot(wavelengths, dOD_SHG_mapCorr, 'bx', label='map corrected', ls = \"None\")\n",
    "#ax.errorbar(wavelengths, dOD_SHG_main, yerr = ErrorCorrectionConvoluted(dOD_SHG_main, scan_corrFactors, peakRad, dRelUmPerPx, dPumpPower), ls = \"None\", capsize =2)\n",
    "'''\n",
    "for ind, time in enumerate(times):\n",
    "    tempVal = dOD_map_reference*paramDictatTime(scan_params, time)[bool_mask]*scan_corrFactors\n",
    "    ax.plot(scan_wavs, tempVal, '1', label=\"%.1f ps\" %(time*1e-3), color = colors[ind])\n",
    "''''''\n",
    "\n",
    "#plot 310 and 330 nm\n",
    "ax.plot([310, 330], [0,0], '1', color = colors[-1])\n",
    "\n",
    "ax.set_xlabel('probe wavelength / nm')\n",
    "ax.set_ylabel(r'$\\mathrm{\\Delta A / a.u.}$')\n",
    "\n",
    "ax.set_xticks(np.arange(300, 701, 50))\n",
    "secax = ax.secondary_xaxis('top', functions=(wavToEnergy, energyToWav))\n",
    "secax.set_xticks(np.round(wavToEnergy(np.array([440, 500, 653])), 2))\n",
    "secax.set_xlabel(r\"$\\mathrm{E_{probe} / eV}$\")\n",
    "ax.legend()\n",
    "ax.grid()\n",
    "\n",
    "\n",
    "\n",
    "times = np.array([1e2, 1e5])\n",
    "colors = ['b', 'r']\n",
    "fig2, ax2 = plt.subplots(1,1, figsize=plotHelperLatex.figSizer(1,2), dpi = 288)\n",
    "'''\n",
    "ax.plot(wavelengths, dOD_SHG_main, 'ro', label='standard correction', ls = \"None\")\n",
    "ax.plot(wavelengths, dOD_SHG_mapCorr, 'bx', label='map corrected', ls = \"None\")\n",
    "#ax.errorbar(wavelengths, dOD_SHG_main, yerr = ErrorCorrectionConvoluted(dOD_SHG_main, scan_corrFactors, peakRad, dRelUmPerPx, dPumpPower), ls = \"None\", capsize =2)\n",
    "'''\n",
    "\n",
    "ind_color2 = ['royalblue', 'lightcoral']\n",
    "for ind, time in enumerate(times):\n",
    "    break\n",
    "    ax2.plot(scan_wavs, dOD_map_reference*paramDictatTime(scan_params, time), colors[ind]+'x', label=\"map corrected: %.1f ps\" %(times[ind]*1e-3))\n",
    "    ax2.plot(scan_wavs, paramDictatTime(scan_params, time), color = ind_color2[ind], marker= '+', linestyle=\"None\", label=\"assuming homogeniety: %.1f ps\" %(times[ind]*1e-3))\n",
    "''''''\n",
    "ax2.set_xlabel('probe wavelength / nm')\n",
    "ax2.set_ylabel(r'$\\mathrm{\\Delta A / a.u.}$')\n",
    "\n",
    "ax2.set_xticks(np.arange(300, 701, 50))\n",
    "secax = ax2.secondary_xaxis('top', functions=(wavToEnergy, energyToWav))\n",
    "secax.set_xticks(np.round(wavToEnergy(np.array([440, 500, 653])), 2))\n",
    "secax.set_xlabel(r\"$\\mathrm{E_{probe} / eV}$\")\n",
    "ax2.legend()\n",
    "ax2.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import scipy.constants as const\n",
    "import plotHelperLatex\n",
    "plotHelperLatex.setMatplotSettings()\n",
    "\n",
    "#copied from above\n",
    "def wavToEnergy(lamb):\n",
    "    #Energy in eV, lamb in nm\n",
    "    return const.h*const.c/lamb*1e9/const.elementary_charge\n",
    "\n",
    "def energyToWav(E):\n",
    "    #Energy in eV, lamb in nm\n",
    "    return const.h*const.c/E*1e9/const.elementary_charge\n",
    "\n",
    "\n",
    "def paramDictatTime(param_dict, time_fs):\n",
    "    return param_dict['A1']*np.exp(-time_fs/param_dict['tau1']) + param_dict['A2']*np.exp(-time_fs/param_dict['tau2'])\n",
    "#import data from excel (terrible choice I know, but I want the visualisation and comparability)\n",
    "\n",
    "def ErrorCorrectionConvoluted(signal, correctionFactor, peakRadiance, dRelUmPerPx, dRelPower):\n",
    "    '''correctionfactor is already divided with peak radiance\\\\\n",
    "    dRelPower = dPower/Power'''\n",
    "    dPeakRadiance = dRelPower*peakRadiance + 2*peakRadiance*dRelUmPerPx\n",
    "    return abs(signal*correctionFactor/peakRadiance*dPeakRadiance)\n",
    "\n",
    "def fitPeaks(x_data, y_data, N_gaussians, centers = [], sigma = [], amplitudes = [], positionBounds = [], function = None):\n",
    "    from scipy.optimize import curve_fit\n",
    "    startParameters = np.ones(3*N_gaussians)\n",
    "    min_bounds = []\n",
    "    max_bounds = []\n",
    "    if len(centers) != N_gaussians:\n",
    "        centers = np.linspace(min(x_data), max(x_data),N_gaussians)\n",
    "    \n",
    "    if len(amplitudes) != N_gaussians:\n",
    "        amplitudes = max(np.abs(y_data))/N_gaussians*np.ones(N_gaussians)\n",
    "    if len(sigma) != N_gaussians:\n",
    "        sigma = np.ones(N_gaussians)*0.01\n",
    "\n",
    "    for i in range(N_gaussians):\n",
    "        startParameters[i*3+1] = sigma[i]\n",
    "        startParameters[i*3] = centers[i]\n",
    "        startParameters[i*3+2] = amplitudes[i]\n",
    "\n",
    "    for i in range(N_gaussians):\n",
    "        if len(positionBounds) == 0:\n",
    "            min_bounds.append(min(x_data))\n",
    "            max_bounds.append(max(x_data))\n",
    "        else:\n",
    "            min_bounds.append(positionBounds[i][0])\n",
    "            max_bounds.append(positionBounds[i][1])\n",
    "        min_bounds.append(0)\n",
    "        max_bounds.append(np.inf)\n",
    "        min_bounds.append(-np.inf)\n",
    "        max_bounds.append(np.inf)\n",
    "    par_bounds = [tuple(min_bounds), tuple(max_bounds)]\n",
    "\n",
    "    if function == None:\n",
    "        function = multiGaussianAdditive\n",
    "\n",
    "    popt, pcov = curve_fit(function, x_data, y_data, \n",
    "            p0 = startParameters, \n",
    "            bounds = par_bounds,\n",
    "            method=\"trf\")\n",
    "    return popt, pcov\n",
    "\n",
    "def multiLorentzianAdditive(x_data, *parameters):\n",
    "    r'''parameters are parameters[number of gaussian, center/gamma/amplitude]'''\n",
    "    y_out = np.zeros(np.shape(x_data))\n",
    "    for cauchyInd in range(0,len(parameters),3):\n",
    "        #y_out += 1/(np.pi*parameters[cauchyInd+1]*(1+np.power((x_data-parameters[cauchyInd])/parameters[cauchyInd+1],2)))\n",
    "        #removing normalisation constant, want it to be 1 in center position\n",
    "        y_out += parameters[cauchyInd+2]/((1+np.power((x_data-parameters[cauchyInd])/parameters[cauchyInd+1],2)))\n",
    "    return y_out\n",
    "\n",
    "excel_path = r\"C:\\Users\\M\\Documents\\phdmatlab\\sqib-pmma-probe-wavelength\\UV_Setup\\new_parallel_pol_pump653nm\\CorrectedPump653ProbeWavelengthScan_UV-extended.xlsx\"\n",
    "SHG_wav_timescan = pd.read_excel(excel_path, sheet_name = \"2024WavelengthScanParameters\", skiprows=[0,1])\n",
    "SHG_main = pd.read_excel(excel_path, sheet_name='2024WavelengthScan', skiprows=[0,1])\n",
    "#print(SHG_main)\n",
    "#print(SHG_main.keys())\n",
    "\n",
    "\n",
    "wavelengths = SHG_main['Probe wavelength / nm']\n",
    "#simple correction without map\n",
    "dOD_SHG_main = SHG_main['cor_dOD / (mOD*m^2/W)']\n",
    "#correction with map\n",
    "dOD_SHG_mapCorr = SHG_main['hypothetical correction']\n",
    "dOD_map_reference = abs(SHG_main['mapReference'])\n",
    "dPumpPower = SHG_main['dRelPumpPower']\n",
    "peakRad = SHG_main['Pump power density / (W/m^2)']\n",
    "\n",
    "\n",
    "scan_wavs = SHG_wav_timescan['Probe wavelength / nm']\n",
    "scan_corrFactors = SHG_wav_timescan['Correction Factor / (W/m^2)^-1']\n",
    "scan_params = {\n",
    "    'A1' : SHG_wav_timescan['A1'],\n",
    "    'A2' : SHG_wav_timescan['A2'],\n",
    "    'tau1' : SHG_wav_timescan['tau1'],\n",
    "    'tau2' : SHG_wav_timescan['tau2'],\n",
    "}\n",
    "\n",
    "\n",
    "#high res zheng\n",
    "\n",
    "zheng_high_res_path = r\"C:\\Users\\M\\Documents\\Books\\masterprojectinformation\\images\\Zheng2020_higherPrecisionRip.csv\"\n",
    "Zheng = pd.read_csv(zheng_high_res_path, sep=\",\")\n",
    "\n",
    "ZhengDict = {}\n",
    "ZhengDict['200fs'] = np.array([Zheng[\"0.2 ps\"][1:], Zheng[\"Y0.2 ps\"][1:]], dtype=float)\n",
    "ZhengDict['2500fs'] = np.array([Zheng[\"2.5 ps\"][1:], Zheng[\"Y2.5 ps\"][1:]], dtype=float)\n",
    "ZhengDict['10ps'] = np.array([Zheng[\"10 ps\"][1:], Zheng[\"Y10 ps\"][1:]], dtype=float)\n",
    "ZhengDict['100ps'] = np.array([Zheng[\"100 ps\"][1:], Zheng[\"Y100 ps\"][1:]], dtype=float)\n",
    "#print(np.array(ZhengDict[\"2500fs\"][0,:],dtype=int))\n",
    "#print(np.array(ZhengDict[\"2500fs\"][0,:],dtype=int) == 680)\n",
    "ZhengModifier = abs(ZhengDict[\"2500fs\"][1,np.array(ZhengDict[\"2500fs\"][0,:],dtype=int) == 679])\n",
    "\n",
    "fig, axs = plt.subplots(1,1, figsize = plotHelperLatex.figSizer(1,2), dpi=288)\n",
    "figc, axc = plt.subplots(2,1, figsize = plotHelperLatex.figSizer(1,1), dpi=288)\n",
    "\n",
    "times = [2e2, 2.5e3, 1e4, 1e5]\n",
    "colors = ['red', 'green', 'orange', 'royalblue']\n",
    "\n",
    "indexMeasureModifier = np.array(scan_wavs, int) == 680\n",
    "modifier_scan_params = {\n",
    "    'A1' : SHG_wav_timescan['A1'][indexMeasureModifier],\n",
    "    'A2' : SHG_wav_timescan['A2'][indexMeasureModifier],\n",
    "    'tau1' : SHG_wav_timescan['tau1'][indexMeasureModifier],\n",
    "    'tau2' : SHG_wav_timescan['tau2'][indexMeasureModifier],\n",
    "}\n",
    "\n",
    "\n",
    "measurementModifier = abs(scan_corrFactors*dOD_map_reference[indexMeasureModifier]*paramDictatTime(modifier_scan_params, times[0]))[0]\n",
    "#print((dOD_map_reference[indexMeasureModifier]*paramDictatTime(scan_params, time))[0])\n",
    "if True:\n",
    "    sizeM = 2\n",
    "    for ind, key in enumerate(ZhengDict):\n",
    "        axs.plot(ZhengDict[key][0,:], ZhengDict[key][1,:]/ZhengModifier, linestyle=\"None\", marker = \".\", markersize= sizeM, color=colors[ind])\n",
    "        axc[0].plot(ZhengDict[key][0,:], ZhengDict[key][1,:]/ZhengModifier, linestyle=\"None\", marker = \".\", markersize= sizeM, color=colors[ind])\n",
    "        axc[1].plot(ZhengDict[key][0,:], ZhengDict[key][1,:]/ZhengModifier, linestyle=\"None\", marker = \".\", markersize= sizeM, color=colors[ind])\n",
    "else:\n",
    "    sizeM = 1\n",
    "    for ind, key in enumerate(ZhengDict):\n",
    "        axs.plot(ZhengDict[key][0,:], ZhengDict[key][1,:]/ZhengModifier, linestyle=\"-\", linewidth = sizeM, marker = \"None\", color=colors[ind])\n",
    "        axc[0].plot(ZhengDict[key][0,:], ZhengDict[key][1,:]/ZhengModifier, linestyle=\"-\", linewidth = sizeM,  marker = \"None\", color=colors[ind])\n",
    "        axc[1].plot(ZhengDict[key][0,:], ZhengDict[key][1,:]/ZhengModifier, linestyle=\"-\", linewidth = sizeM,  marker = \"None\", color=colors[ind])\n",
    "\n",
    "for ind, time in enumerate(times):\n",
    "    tempVal = scan_corrFactors*dOD_map_reference*paramDictatTime(scan_params, time)/measurementModifier\n",
    "\n",
    "    axs.plot(scan_wavs, tempVal, '1', color = colors[ind], label=\"%.1f ps\" %(time*1e-3))\n",
    "    axc[0].plot(scan_wavs, tempVal, '1', color = colors[ind], label=\"%.1f ps\" %(time*1e-3))\n",
    "    axc[1].plot(scan_wavs, tempVal, '1', color = colors[ind], label=\"%.1f ps\" %(time*1e-3))\n",
    "#plotting 310 and 330 by hand\n",
    "axs.plot([310, 330], [0,0], '1', color = colors[-1], label=\"%.1f ps\" %(times[-1]*1e-3))\n",
    "axc[0].plot([310, 330], [0,0], '1', color = colors[-1], label=\"%.1f ps\" %(times[-1]*1e-3))\n",
    "axc[1].plot([310, 330], [0,0], '1', color = colors[-1], label=\"%.1f ps\" %(times[-1]*1e-3))\n",
    "\n",
    "#############plot the fitting of with cauchy functions##############################\n",
    "y_dataFit = scan_corrFactors*dOD_map_reference*paramDictatTime(scan_params, times[0])/measurementModifier\n",
    "y_dataFit = y_dataFit[1:-2]\n",
    "wav_dataFit = scan_wavs[1:-2]\n",
    "#do nan-check\n",
    "#nanBool = np.isnan(y_dataFit)\n",
    "\n",
    "\n",
    "wav_range = np.linspace(350,550,500)\n",
    "axs.plot(wav_range, multiLorentzianAdditive(wavToEnergy(wav_range), *signalFit), label=r\"$\\sum$ fits\", alpha=0.5,linestyle=\"-\", color = \"m\")\n",
    "axc[1].plot(wav_range, multiLorentzianAdditive(wavToEnergy(wav_range), *signalFit), label=r\"$\\sum$ fits\", alpha=0.5,linestyle=\"-\", color = \"m\")\n",
    "color_fits = [\"blue\", \"green\", \"orange\"]\n",
    "for i in range(0,len(signalFit),3):\n",
    "    #break\n",
    "    axs.plot(wav_range, multiLorentzianAdditive(wavToEnergy(wav_range), *signalFit[i:i+3]), label=\"fit \"+str(int(i/3)), alpha=0.5,linestyle=\"-\", color = color_fits[int(i/3)])\n",
    "    axc[1].plot(wav_range, multiLorentzianAdditive(wavToEnergy(wav_range), *signalFit[i:i+3]), label=\"fit \"+str(int(i/3)), alpha=0.5,linestyle=\"-\", color = color_fits[int(i/3)])\n",
    "\n",
    "\n",
    "secax = axs.secondary_xaxis('top', functions=(wavToEnergy, energyToWav))\n",
    "secax.set_xticks(np.round(wavToEnergy(np.array([440, 500, 653])), 2))\n",
    "secax.set_xlabel(r\"$\\mathrm{E_{probe} / eV}$\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "axs.set_xlabel('probe wavelength / nm')\n",
    "axs.set_ylabel(r'relative $\\Delta A$ / a.u.')\n",
    "axs.grid(True)\n",
    "\n",
    "\n",
    "\n",
    "#custom legend\n",
    "from matplotlib.lines import Line2D\n",
    "legend_items = [Line2D([0], [0], color = \"black\", label=\"Zheng et al.\", marker=\".\", linestyle=\"None\"),\n",
    "                Line2D([0], [0], color = \"black\", label=\"SHG setup\", marker=\"1\",linestyle=\"None\")]\n",
    "for ind in range(len(times)):\n",
    "    legend_items.append(Line2D([0], [0], color = colors[ind], label=\"%.1f ps\" %(times[ind]*1e-3), marker=\"s\", linestyle=\"None\"))\n",
    "\n",
    "#introduce cauchy fits to legend\n",
    "#legend_items.append(Line2D([0], [0], label=r\"$\\sum$ fits\", linestyle=\"-\", alpha=0.5, color = \"m\"))\n",
    "for l2d in range(3):\n",
    "    break\n",
    "    legend_items.append(Line2D([0], [0], label=\"fit \"+str(int(l2d)), linestyle=\"-\", alpha=0.5, color = color_fits[l2d]))\n",
    "axs.legend(handles=legend_items)\n",
    "\n",
    "\n",
    "for i in range(2):\n",
    "    secax2 = axc[i].secondary_xaxis('top', functions=(wavToEnergy, energyToWav))\n",
    "    secax2.set_xticks(np.round(wavToEnergy(np.array([440, 500, 653])), 2))\n",
    "    secax2.set_xlabel(r\"$\\mathrm{E_{probe} / eV}$\")\n",
    "    axc[i].set_xlabel('probe wavelength / nm')\n",
    "    axc[i].set_ylabel(r'relative $\\Delta A$ / a.u.')\n",
    "    #axc[i].legend(handles=legend_items)\n",
    "    axc[i].grid(visible=True)\n",
    "axc[1].legend(handles=legend_items)\n",
    "#axs.set_ylim((0,1.5))\n",
    "#axs.set_xlim((300, 550))\n",
    "axc[1].set_xlim((300,550))\n",
    "axc[1].set_ylim((0,1.5))\n",
    "\n",
    "#plt.grid(True)\n",
    "#plt.show()\n",
    "plt.tight_layout()\n",
    "\n",
    "#attempt the alternative moving mean at a width of 10 nm aka +- 5 nm\n",
    "gaussian = lambda wavs, centerwav: 1/np.sqrt(2*np.pi)/5*np.exp(-(centerwav-wavs)**2/(2*5**2))\n",
    "ZhengOurWavelengths = np.zeros((len(ZhengDict.keys()), len(wavelengths)))\n",
    "for wav_ind, wav in enumerate(wavelengths):\n",
    "    for key_ind, key in enumerate(ZhengDict.keys()):\n",
    "        #print(key)\n",
    "        wav_bool_array = (wav- 30< ZhengDict[key][0,:]) & (wav +30 > ZhengDict[key][0,:])\n",
    "        #bool_array = (delays[indWav,:] > plotDelay[indDelay]) & (delays[indWav,:] < plotDelay[indDelay] + 1e3/(n_subticks))\n",
    "        #ZhengOurWavelengths[key_ind, wav_ind] = np.sum(ZhengDict[key][1,wav_bool_array])\n",
    "        ZhengOurWavelengths[key_ind, wav_ind] = np.sum(gaussian(ZhengDict[key][0,wav_bool_array], wav)*ZhengDict[key][1,wav_bool_array])\n",
    "        #print(gaussian(ZhengDict[key][0,:], wav)*ZhengDict[key][1,:])\n",
    "\"\"\"\n",
    "ax2.plot(wavelengths, scan_corrFactors*dOD_map_reference*paramDictatTime(scan_params, 2e2)/measurementModifier, linestyle=\"None\", marker=\"1\", color='r')\n",
    "\n",
    "time_ind = 2\n",
    "ax2.plot(wavelengths, ZhengOurWavelengths[time_ind]/abs(ZhengOurWavelengths[0,indexMeasureModifier]), linestyle=\"None\", marker=\".\")\n",
    "ax2.plot(ZhengDict[\"200fs\"][0,:], ZhengDict[\"200fs\"][1,:]/ZhengModifier, linestyle=\"None\", marker = \".\", color=colors[ind])\"\"\"\n",
    "#second plot --- plotting 2.5 ps signal\n",
    "fig2, ax2 = plt.subplots(1,1,figsize=plotHelperLatex.figSizer(1,3), dpi=288)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import scipy.constants as const\n",
    "import plotHelperLatex\n",
    "plotHelperLatex.setMatplotSettings()\n",
    "\n",
    "#copied from above\n",
    "def wavToEnergy(lamb):\n",
    "    #Energy in eV, lamb in nm\n",
    "    return const.h*const.c/lamb*1e9/const.elementary_charge\n",
    "\n",
    "def energyToWav(E):\n",
    "    #Energy in eV, lamb in nm\n",
    "    return const.h*const.c/E*1e9/const.elementary_charge\n",
    "\n",
    "\n",
    "def paramDictatTime(param_dict, time_fs):\n",
    "    return param_dict['A1']*np.exp(-time_fs/param_dict['tau1']) + param_dict['A2']*np.exp(-time_fs/param_dict['tau2'])\n",
    "#import data from excel (terrible choice I know, but I want the visualisation and comparability)\n",
    "\n",
    "def ErrorCorrectionConvoluted(signal, correctionFactor, peakRadiance, dRelUmPerPx, dRelPower):\n",
    "    '''correctionfactor is already divided with peak radiance\\\\\n",
    "    dRelPower = dPower/Power'''\n",
    "    dPeakRadiance = dRelPower*peakRadiance + 2*peakRadiance*dRelUmPerPx\n",
    "    return abs(signal*correctionFactor/peakRadiance*dPeakRadiance)\n",
    "\n",
    "def fitPeaks(x_data, y_data, N_gaussians, centers = [], sigma = [], amplitudes = [], positionBounds = [], ampBounds = [], sigBounds = [], function = None):\n",
    "    from scipy.optimize import curve_fit\n",
    "    startParameters = np.ones(3*N_gaussians)\n",
    "    min_bounds = []\n",
    "    max_bounds = []\n",
    "    if len(centers) != N_gaussians:\n",
    "        centers = np.linspace(min(x_data), max(x_data),N_gaussians)\n",
    "    \n",
    "    if len(amplitudes) != N_gaussians:\n",
    "        amplitudes = max(np.abs(y_data))/N_gaussians*np.ones(N_gaussians)\n",
    "    if len(sigma) != N_gaussians:\n",
    "        sigma = np.ones(N_gaussians)*0.01\n",
    "\n",
    "    for i in range(N_gaussians):\n",
    "        startParameters[i*3+1] = sigma[i]\n",
    "        startParameters[i*3] = centers[i]\n",
    "        startParameters[i*3+2] = amplitudes[i]\n",
    "\n",
    "    for i in range(N_gaussians):\n",
    "        if len(positionBounds) == 0:\n",
    "            min_bounds.append(min(x_data))\n",
    "            max_bounds.append(max(x_data))\n",
    "        else:\n",
    "            min_bounds.append(positionBounds[i][0])\n",
    "            max_bounds.append(positionBounds[i][1])\n",
    "        if len(sigBounds)==0:\n",
    "            min_bounds.append(0)\n",
    "            max_bounds.append(np.inf)\n",
    "        else:\n",
    "            min_bounds.append(sigBounds[i][0])\n",
    "            max_bounds.append(sigBounds[i][1])\n",
    "        if len(ampBounds) == 0:\n",
    "            min_bounds.append(-np.inf)\n",
    "            max_bounds.append(np.inf)\n",
    "        else:\n",
    "            min_bounds.append(ampBounds[0])\n",
    "            max_bounds.append(ampBounds[1])\n",
    "    par_bounds = [tuple(min_bounds), tuple(max_bounds)]\n",
    "\n",
    "\n",
    "    popt, pcov = curve_fit(function, x_data, y_data, \n",
    "            p0 = startParameters, \n",
    "            bounds = par_bounds,\n",
    "            method=\"trf\")\n",
    "    return popt, pcov\n",
    "\n",
    "def multiLorentzianAdditive(x_data, *parameters):\n",
    "    r'''parameters are parameters[number of gaussian, center/gamma/amplitude]'''\n",
    "    y_out = np.zeros(np.shape(x_data))\n",
    "    for cauchyInd in range(0,len(parameters),3):\n",
    "        #y_out += 1/(np.pi*parameters[cauchyInd+1]*(1+np.power((x_data-parameters[cauchyInd])/parameters[cauchyInd+1],2)))\n",
    "        #removing normalisation constant, want it to be 1 in center position\n",
    "        y_out += parameters[cauchyInd+2]/((1+np.power((x_data-parameters[cauchyInd])/parameters[cauchyInd+1],2)))\n",
    "    return y_out\n",
    "\n",
    "def multiGaussianAdditive(x_data, *parameters):\n",
    "    r'''parameters are parameters[number of gaussian, center/sig/amplitude]'''\n",
    "    y_out = np.zeros(np.shape(x_data))\n",
    "    for gaussInd in range(0,len(parameters),3):\n",
    "        y_out += parameters[gaussInd+2]*np.exp(-np.power(x_data-parameters[gaussInd+0], 2)/(2*np.power(parameters[gaussInd+1],2)))\n",
    "    return y_out\n",
    "\n",
    "excel_path = r\"C:\\Users\\M\\Documents\\phdmatlab\\sqib-pmma-probe-wavelength\\UV_Setup\\new_parallel_pol_pump653nm\\CorrectedPump653ProbeWavelengthScan_UV-extended.xlsx\"\n",
    "SHG_wav_timescan = pd.read_excel(excel_path, sheet_name = \"2024WavelengthScanParameters\", skiprows=[0,1])\n",
    "SHG_main = pd.read_excel(excel_path, sheet_name='2024WavelengthScan', skiprows=[0,1])\n",
    "#print(SHG_main)\n",
    "#print(SHG_main.keys())\n",
    "\n",
    "\n",
    "wavelengths = SHG_main['Probe wavelength / nm']\n",
    "#simple correction without map\n",
    "dOD_SHG_main = SHG_main['cor_dOD / (mOD*m^2/W)']\n",
    "#correction with map\n",
    "dOD_SHG_mapCorr = SHG_main['hypothetical correction']\n",
    "dOD_map_reference = abs(SHG_main['mapReference'])\n",
    "dPumpPower = SHG_main['dRelPumpPower']\n",
    "peakRad = SHG_main['Pump power density / (W/m^2)']\n",
    "\n",
    "\n",
    "scan_wavs = SHG_wav_timescan['Probe wavelength / nm']\n",
    "scan_corrFactors = SHG_wav_timescan['Correction Factor / (W/m^2)^-1']\n",
    "scan_params = {\n",
    "    'A1' : SHG_wav_timescan['A1'],\n",
    "    'A2' : SHG_wav_timescan['A2'],\n",
    "    'tau1' : SHG_wav_timescan['tau1'],\n",
    "    'tau2' : SHG_wav_timescan['tau2'],\n",
    "}\n",
    "\n",
    "scan_corrFactors[7] = np.nan\n",
    "#high res zheng\n",
    "\n",
    "zheng_high_res_path = r\"C:\\Users\\M\\Documents\\Books\\masterprojectinformation\\images\\Zheng2020_higherPrecisionRip.csv\"\n",
    "Zheng = pd.read_csv(zheng_high_res_path, sep=\",\")\n",
    "\n",
    "ZhengDict = {}\n",
    "ZhengDict['200fs'] = np.array([Zheng[\"0.2 ps\"][1:], Zheng[\"Y0.2 ps\"][1:]], dtype=float)\n",
    "ZhengDict['2500fs'] = np.array([Zheng[\"2.5 ps\"][1:], Zheng[\"Y2.5 ps\"][1:]], dtype=float)\n",
    "ZhengDict['10ps'] = np.array([Zheng[\"10 ps\"][1:], Zheng[\"Y10 ps\"][1:]], dtype=float)\n",
    "ZhengDict['100ps'] = np.array([Zheng[\"100 ps\"][1:], Zheng[\"Y100 ps\"][1:]], dtype=float)\n",
    "#print(np.array(ZhengDict[\"2500fs\"][0,:],dtype=int))\n",
    "#print(np.array(ZhengDict[\"2500fs\"][0,:],dtype=int) == 680)\n",
    "ZhengModifier = abs(ZhengDict[\"2500fs\"][1,np.array(ZhengDict[\"2500fs\"][0,:],dtype=int) == 679])\n",
    "\n",
    "fig, axs = plt.subplots(1,1, figsize = plotHelperLatex.figSizer(1,2), dpi=288)\n",
    "#figc, axc = plt.subplots(2,1, figsize = plotHelperLatex.figSizer(1, 1.4), dpi=288)\n",
    "\n",
    "#times = [2e2, 2.5e3, 1e4, 1e5]\n",
    "times = [10e3]\n",
    "colors = ['red', 'green', 'orange', 'royalblue']\n",
    "\n",
    "indexMeasureModifier = np.array(scan_wavs, int) == 680\n",
    "modifier_scan_params = {\n",
    "    'A1' : SHG_wav_timescan['A1'][indexMeasureModifier],\n",
    "    'A2' : SHG_wav_timescan['A2'][indexMeasureModifier],\n",
    "    'tau1' : SHG_wav_timescan['tau1'][indexMeasureModifier],\n",
    "    'tau2' : SHG_wav_timescan['tau2'][indexMeasureModifier],\n",
    "}\n",
    "ZhengRefSig = np.array(Zheng[\"Y10 ps\"][1:], dtype=float)\n",
    "ZhengRefWav = np.array(Zheng[\"10 ps\"][1:], dtype=float)\n",
    "bool_mask = np.invert(np.isnan(ZhengRefSig))\n",
    "ZhengRefSig = np.array(ZhengRefSig[bool_mask])\n",
    "ZhengRefWav = ZhengRefWav[bool_mask]\n",
    "\n",
    "measurementModifier = abs(scan_corrFactors*dOD_map_reference[indexMeasureModifier]*paramDictatTime(modifier_scan_params, times[0]))[0]\n",
    "#print((dOD_map_reference[indexMeasureModifier]*paramDictatTime(scan_params, time))[0])\n",
    "\n",
    "\n",
    "zhengFit, zhengCov = fitPeaks(wavToEnergy(ZhengRefWav), ZhengRefSig/ZhengModifier,2, [2.5, 2.75], [0.1,0.1], [1, 1], positionBounds=[[2, 3], [2, 3]], function=multiLorentzianAdditive, sigBounds=[[0.02,0.9], [0.1,np.inf]], ampBounds=[0.4, 2])\n",
    "#zhengFit, zhengCov = fitPeaks(wavToEnergy(ZhengRefWav), ZhengRefSig/ZhengModifier,2, [2.82, 2.48], [0.2,0.05], [0.35, 0.7], positionBounds=[[2.76, 2.83], [2.3, 2.7]], function=multiGaussianAdditive)\n",
    "print(zhengFit)\n",
    "\n",
    "axs.plot(ZhengRefWav, ZhengRefSig/ZhengModifier, linestyle=\"None\", marker = \".\", markersize= 2, color=\"r\")\n",
    "\n",
    "\n",
    "\n",
    "for ind, time in enumerate(times):\n",
    "    axs.plot(scan_wavs, scan_corrFactors*dOD_map_reference*paramDictatTime(scan_params, time)/measurementModifier, '1', color = \"b\", label=\"%.1f ps\" %(time*1e-3))\n",
    "\n",
    "#plotting 310 and 330 by hand\n",
    "axs.plot([310, 330], [0,0], '1', color = \"b\")\n",
    "\n",
    "\n",
    "#############plot the fitting of with cauchy functions##############################\n",
    "y_dataFit = scan_corrFactors*dOD_map_reference*paramDictatTime(scan_params, times[0])/measurementModifier\n",
    "y_dataFit = y_dataFit[1:-2]\n",
    "wav_dataFit = scan_wavs[1:-2]\n",
    "#get rid of nan\n",
    "bool_mask = np.invert(np.isnan(y_dataFit))\n",
    "y_dataFit = np.array(y_dataFit[bool_mask])\n",
    "wav_dataFit = wav_dataFit[bool_mask]\n",
    "\n",
    "signalFit, signalCov = fitPeaks(wavToEnergy(wav_dataFit), y_dataFit, 3, [2.75, 2.48, 3.15], [0.1,0.04, 0.02], [0.5, 0.5, 0.1], positionBounds=[[2.74, 2.83], [2.3, 2.7], [3.015,3.60]], function=multiLorentzianAdditive, ampBounds=[0,np.inf])\n",
    "\n",
    "\n",
    "wav_range = np.linspace(350,550,500)\n",
    "axs.plot(wav_range, multiLorentzianAdditive(wavToEnergy(wav_range), *signalFit), label=r\"$\\sum$ fits\", alpha=0.5,linestyle=\"-\", color = \"b\")\n",
    "axs.plot(wav_range, multiLorentzianAdditive(wavToEnergy(wav_range), *zhengFit), label=r\"$\\sum$ fits\", alpha=0.5,linestyle=\"-\", color = \"r\")\n",
    "#axs.plot(wav_range, multiGaussianAdditive(wavToEnergy(wav_range), *zhengFit), label=r\"$\\sum$ fits\", alpha=0.5,linestyle=\"-\", color = \"r\")\n",
    "color_fits = [\"blue\", \"green\", \"purple\"]\n",
    "for i in range(0,len(signalFit),3):\n",
    "    #break\n",
    "    axs.plot(wav_range, multiLorentzianAdditive(wavToEnergy(wav_range), *signalFit[i:i+3]), label=\"fit \"+str(int(i/3)), alpha=0.3,linestyle=\"--\", color = \"b\")\n",
    "for i in range(0,len(zhengFit),3):\n",
    "    #axs.plot(wav_range, multiGaussianAdditive(wavToEnergy(wav_range), *zhengFit[i:i+3]), label=\"fit \"+str(int(i/3)), alpha=0.3,linestyle=\"--\", color = \"r\")\n",
    "    axs.plot(wav_range, multiLorentzianAdditive(wavToEnergy(wav_range), *zhengFit[i:i+3]), label=\"fit \"+str(int(i/3)), alpha=0.3,linestyle=\"--\", color = \"r\")\n",
    "secax = axs.secondary_xaxis('top', functions=(wavToEnergy, energyToWav))\n",
    "secax.set_xticks(np.round(wavToEnergy(np.array([410,440, 500, 653])), 2))\n",
    "secax.set_xlabel(r\"$\\mathrm{E_{probe} / eV}$\")\n",
    "\n",
    "\n",
    "\n",
    "axs.set_xlim((300,550))\n",
    "axs.set_ylim((0,1.2))\n",
    "axs.set_xlabel('probe wavelength / nm')\n",
    "axs.set_ylabel(r'relative $\\Delta A$ / a.u.')\n",
    "axs.grid(True)\n",
    "\n",
    "print(signalFit)\n",
    "\n",
    "#custom legend\n",
    "from matplotlib.lines import Line2D\n",
    "legend_single = [Line2D([0], [0], color = \"r\", label=\"Zheng et al.\", marker=\".\", linestyle=\"None\"),\n",
    "                    Line2D([0], [0], color = \"r\", label=r\"Zheng $\\sum$ fits\", marker=\"None\",linestyle=\"-\", alpha=0.5),\n",
    "                    Line2D([0], [0], color = \"r\", label=r\"Zheng fits\", marker=\"None\",linestyle=\"--\", alpha=0.3),\n",
    "                    Line2D([0], [0], color = \"b\", label=\"SHG setup\", marker=\"1\",linestyle=\"None\"), \n",
    "                    Line2D([0], [0], color = \"b\", label=r\"SHG $\\sum$ fits\", marker=\"None\",linestyle=\"-\", alpha=0.5),\n",
    "                    Line2D([0], [0], color = \"b\", label=r\"SHG fits\", marker=\"None\",linestyle=\"--\", alpha=0.3)]\n",
    "\n",
    "axs.legend(handles=legend_single)\n",
    "legend_itemsZheng = [Line2D([0], [0], color = \"r\", label=\" 2.5 ps Zheng et al.\", marker=\".\", linestyle=\"None\")]\n",
    "legend_itemsSHG = [Line2D([0], [0], color = \"r\", label=\"2.5 ps SHG setup\", marker=\"1\",linestyle=\"None\")]\n",
    "for ind in range(len(times)):\n",
    "    break\n",
    "    legend_items.append(Line2D([0], [0], color = colors[ind], label=\"%.1f ps\" %(times[ind]*1e-3), marker=\"s\", linestyle=\"None\"))\n",
    "\n",
    "#introduce cauchy fits to legend\n",
    "legend_itemsZheng.append(Line2D([0], [0], label=r\"$\\sum$ fits\", linestyle=\"-\", alpha=0.5, color = \"m\"))\n",
    "legend_itemsSHG.append(Line2D([0], [0], label=r\"$\\sum$ fits\", linestyle=\"-\", alpha=0.5, color = \"m\"))\n",
    "for l2d in range(3):\n",
    "    #break\n",
    "    legend_itemsSHG.append(Line2D([0], [0], label=\"fit \"+str(int(l2d)), linestyle=\"-\", alpha=0.5, color = color_fits[l2d]))\n",
    "    if l2d < 2:\n",
    "        legend_itemsZheng.append(Line2D([0], [0], label=\"fit \"+str(int(l2d)), linestyle=\"-\", alpha=0.5, color = color_fits[l2d]))\n",
    "#axs.legend(handles=legend_items)\n",
    "\n",
    "\n",
    "\n",
    "#plt.grid(True)\n",
    "#plt.show()\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this here is supposed to show 'raw' data over wavelength\n",
    "#copied most from above\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import constants as const\n",
    "import numpy as np\n",
    "import plotHelperLatex\n",
    "plotHelperLatex.setMatplotSettings()\n",
    "import fileParsingMethods\n",
    "import SeriesDegradation\n",
    "import json\n",
    "\n",
    "umPerPx = 6.949\n",
    "dumPerPx = 4E-2\n",
    "dRelUmPerPx = dumPerPx/umPerPx\n",
    "\n",
    "def wavToEnergy(lamb):\n",
    "    #Energy in eV, lamb in nm\n",
    "    return const.h*const.c/lamb*1e9/const.elementary_charge\n",
    "\n",
    "def energyToWav(E):\n",
    "    #Energy in eV, lamb in nm\n",
    "    return const.h*const.c/E*1e9/const.elementary_charge\n",
    "\n",
    "def paramDictatTime(param_dict, time_fs):\n",
    "    return param_dict['A1']*np.exp(-time_fs/param_dict['tau1']) + param_dict['A2']*np.exp(-time_fs/param_dict['tau2'])\n",
    "#import data from excel (terrible choice I know, but I want the visualisation and comparability)\n",
    "\n",
    "def ErrorCorrectionConvoluted(signal, correctionFactor, peakRadiance, dRelUmPerPx, dRelPower):\n",
    "    '''correctionfactor is already divided with peak radiance\\\\\n",
    "    dRelPower = dPower/Power'''\n",
    "    dPeakRadiance = dRelPower*peakRadiance + 2*peakRadiance*dRelUmPerPx\n",
    "    return abs(signal*correctionFactor/peakRadiance*dPeakRadiance)\n",
    "\n",
    "#doing this manually because I hate myself, but not enough to automate it\n",
    "#[directory, filename, fitJSON for t0]\n",
    "filePaths = []\n",
    "#STD\n",
    "filePaths.append([r\"C:\\Users\\M\\Documents\\phdmatlab\\sqib-pmma-probe-wavelength\\UV_Setup\\new_parallel_pol_pump653nm\\STD-680\", r\"saturation_2024-01-16_14-09.mat\",  r\"TAfitPump653Probe680_DecayCorrected.JSON\", r\"SummaryPump653Probe680.JSON\"])\n",
    "filePaths.append([r\"C:\\Users\\M\\Documents\\phdmatlab\\sqib-pmma-probe-wavelength\\UV_Setup\\new_parallel_pol_pump653nm\\STD-520\", r\"saturation_2024-01-16_15-21.mat\",  r\"TAfitPump653Probe520_DecayCorrected.JSON\", r\"SummaryPump653Probe520.JSON\"])\n",
    "filePaths.append([r\"C:\\Users\\M\\Documents\\phdmatlab\\sqib-pmma-probe-wavelength\\UV_Setup\\new_parallel_pol_pump653nm\\STD-502\", r\"saturation_2024-01-16_14-51.mat\",  r\"TAfitPump653Probe502_DecayCorrected.JSON\", r\"SummaryPump653Probe502.JSON\"])\n",
    "filePaths.append([r\"C:\\Users\\M\\Documents\\phdmatlab\\sqib-pmma-probe-wavelength\\UV_Setup\\new_parallel_pol_pump653nm\\STD-493\", r\"saturation_2024-01-19_14-24.mat\",  r\"TAfitPump653Probe493_DecayCorrected.JSON\", r\"SummaryPump653Probe493Caution.JSON\"])\n",
    "#SHG\n",
    "filePaths.append([r\"C:\\Users\\M\\Documents\\phdmatlab\\sqib-pmma-probe-wavelength\\UV_Setup\\new_parallel_pol_pump653nm\\SHG-468\", r\"saturation_2024-01-16_18-38.mat\",  r\"TAfitPump653Probe468_DecayCorrected.JSON\", r\"SummaryPump653Probe468.JSON\"])\n",
    "filePaths.append([r\"C:\\Users\\M\\Documents\\phdmatlab\\sqib-pmma-probe-wavelength\\UV_Setup\\new_parallel_pol_pump653nm\\SHG-460\", r\"saturation_2024-01-18_17-34.mat\",  r\"TAfitPump653Probe460_DecayCorrected.JSON\", r\"SummaryPump653Probe460Caution.JSON\"])\n",
    "filePaths.append([r\"C:\\Users\\M\\Documents\\phdmatlab\\sqib-pmma-probe-wavelength\\UV_Setup\\new_parallel_pol_pump653nm\\SHG-450\", r\"saturation_2024-01-18_11-28.mat\",  r\"TAfitPump653Probe450_DecayCorrected.JSON\", r\"SummaryPump653Probe450.JSON\"])\n",
    "filePaths.append([r\"C:\\Users\\M\\Documents\\phdmatlab\\sqib-pmma-probe-wavelength\\UV_Setup\\new_parallel_pol_pump653nm\\SHG-440\", r\"saturation_2024-01-16_19-07.mat\",  r\"TAfitPump653Probe440_DecayCorrected.JSON\", r\"SummaryPump653Probe440.JSON\"])\n",
    "filePaths.append([r\"C:\\Users\\M\\Documents\\phdmatlab\\sqib-pmma-probe-wavelength\\UV_Setup\\new_parallel_pol_pump653nm\\SHG-430\", r\"saturation_2024-01-18_10-52.mat\",  r\"TAfitPump653Probe430_DecayCorrected.JSON\", r\"SummaryPump653Probe430.JSON\"])\n",
    "filePaths.append([r\"C:\\Users\\M\\Documents\\phdmatlab\\sqib-pmma-probe-wavelength\\UV_Setup\\new_parallel_pol_pump653nm\\SHG-420\", r\"saturation_2024-01-17_14-46.mat\",  r\"TAfitPump653Probe420_DecayCorrected.JSON\", r\"SummaryPump653Probe420.JSON\"])\n",
    "filePaths.append([r\"C:\\Users\\M\\Documents\\phdmatlab\\sqib-pmma-probe-wavelength\\UV_Setup\\new_parallel_pol_pump653nm\\SHG-410\", r\"saturation_2024-01-19_13-41.mat\",  r\"TAfitPump653Probe410_DecayCorrected.JSON\", r\"SummaryPump653Probe410Caution.JSON\"])\n",
    "filePaths.append([r\"C:\\Users\\M\\Documents\\phdmatlab\\sqib-pmma-probe-wavelength\\UV_Setup\\new_parallel_pol_pump653nm\\SHG-400\", r\"saturation_2024-01-17_15-26.mat\",  r\"TAfitPump653Probe400_DecayCorrected.JSON\", r\"SummaryPump653Probe400.JSON\"])\n",
    "filePaths.append([r\"C:\\Users\\M\\Documents\\phdmatlab\\sqib-pmma-probe-wavelength\\UV_Setup\\new_parallel_pol_pump653nm\\SHG-390\", r\"saturation_2024-01-18_12-03.mat\",  r\"TAfitPump653Probe390_DecayCorrected.JSON\", r\"SummaryPump653Probe390.JSON\"])\n",
    "filePaths.append([r\"C:\\Users\\M\\Documents\\phdmatlab\\sqib-pmma-probe-wavelength\\UV_Setup\\new_parallel_pol_pump653nm\\SHG-380\", r\"saturation_2024-01-17_16-31.mat\",  r\"TAfitPump653Probe380_2_DecayCorrected.JSON\", r\"SummaryPump653Probe380_2.JSON\"])\n",
    "filePaths.append([r\"C:\\Users\\M\\Documents\\phdmatlab\\sqib-pmma-probe-wavelength\\UV_Setup\\new_parallel_pol_pump653nm\\SHG-370\", r\"saturation_2024-01-17_17-11.mat\",  r\"TAfitPump653Probe370_DecayCorrected.JSON\", r\"SummaryPump653Probe370.JSON\"])\n",
    "filePaths.append([r\"C:\\Users\\M\\Documents\\phdmatlab\\sqib-pmma-probe-wavelength\\UV_Setup\\new_parallel_pol_pump653nm\\SHG-360\", r\"saturation_2024-01-18_15-50.mat\",  r\"TAfitPump653Probe360_DecayCorrected.JSON\", r\"SummaryPump653Probe360_2.JSON\"])\n",
    "filePaths.append([r\"C:\\Users\\M\\Documents\\phdmatlab\\sqib-pmma-probe-wavelength\\UV_Setup\\new_parallel_pol_pump653nm\\SHG-350\", r\"saturation_2024-01-18_16-39.mat\",  r\"TAfitPump653Probe350_DecayCorrected.JSON\", r\"SummaryPump653Probe350.JSON\"])\n",
    "\n",
    "#import map correction\n",
    "excel_path = r\"C:\\Users\\M\\Documents\\phdmatlab\\sqib-pmma-probe-wavelength\\UV_Setup\\new_parallel_pol_pump653nm\\CorrectedPump653ProbeWavelengthScan_UV-extended.xlsx\"\n",
    "SHG_main = pd.read_excel(excel_path, sheet_name='2024WavelengthScan', skiprows=[0,1], usecols=[\"Probe wavelength / nm\", \"mapReference\"])\n",
    "\n",
    "SHG_main = SHG_main.sort_values(by=\"Probe wavelength / nm\", ascending=False)\n",
    "SHG_main.drop_duplicates()\n",
    "SHG_main= SHG_main[:-2]\n",
    "#print(SHG_main)\n",
    "def updateFitJSON(fitJSONpath,summaryJSONpath, referencePower, referenceDecay):\n",
    "    #beware this only works for single entries\n",
    "    fitJSONfile = open(fitJSONpath)\n",
    "    fitJSON = json.load(fitJSONfile)\n",
    "    fitJSONfile.close()\n",
    "    sumJSONfile = open(summaryJSONpath)\n",
    "    sumJSON = json.load(sumJSONfile)\n",
    "    sumJSONfile.close()\n",
    "    ownPower = sumJSON[\"Pump power density: W/m^2\"]\n",
    "    fitJSON[\"entries\"][0][\"degradePowerRatio\"] = ownPower/referencePower\n",
    "    fitJSON[\"entries\"][0][\"tauExpDegrade\"] = referenceDecay\n",
    "    #print(fitJSON)\n",
    "    fitJSONfile = open(fitJSONpath, 'w')\n",
    "    json.dump(fitJSON,fitJSONfile)\n",
    "    fitJSONfile.truncate()\n",
    "    fitJSONfile.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dOD_map_reference = SHG_main[\"mapReference\"]\n",
    "dOD_map_reference = abs(dOD_map_reference/np.mean(dOD_map_reference))\n",
    "pRatioReference = 1575\n",
    "#now grab the data, correct/background substract it it and stuff it into an array as a mean\n",
    "wav_vec = [680, 520, 502, 493, 468, 460, 450, 440, 430, 420, 410, 400, 390, 380, 370, 360, 350]\n",
    "bgLen = np.ones(np.shape(wav_vec), dtype=int)*25\n",
    "#the linear background ones need more precise backgroundlengths\n",
    "bgLen[[0,1,2,6,8]] = [40, 30, 25, 35, 35]\n",
    "data_raw = []\n",
    "delays = []\n",
    "t0 = []\n",
    "for ind, path_list in enumerate(filePaths):\n",
    "    #load json with data needed\n",
    "    #overlap JSON\n",
    "    json_file = open(path_list[0] + r\"\\\\\"[0] + path_list[3])\n",
    "    overlapCorrection = json.load(json_file)[\"Correction Factor: per W/m^2 pump power\"]\n",
    "    #fit JSON\n",
    "    #update if needed first\n",
    "    #updateFitJSON(path_list[0] + r\"\\\\\"[0] + path_list[2], path_list[0] + r\"\\\\\"[0] + path_list[3], pRatioReference, 12600)\n",
    "    json_file = open(path_list[0] + r\"\\\\\"[0] + path_list[2])\n",
    "    temp_JSON = json.load(json_file)[\"entries\"][0]\n",
    "\n",
    "    \n",
    "    #print(temp_JSON)\n",
    "    if ('bgParam' in temp_JSON.keys()) and (temp_JSON['bgParam'][0] != 0):\n",
    "        linBgBool = True\n",
    "    else:\n",
    "        linBgBool = False\n",
    "    \n",
    "    tempdata, _, degradeFactors, tempdelay, _ = SeriesDegradation.autoCompensation(path_list[1], dirPath = path_list[0], degConst = temp_JSON[\"tauExpDegrade\"], p_ratio = temp_JSON[\"degradePowerRatio\"], linearBg=linBgBool, backgroundMean=bgLen[ind])\n",
    "    data_raw.append(np.mean(overlapCorrection*dOD_map_reference[ind]*tempdata*degradeFactors, axis = 0))\n",
    "    t0.append(temp_JSON[\"startParameters\"][0][\"position\"])\n",
    "    #print(t0)\n",
    "    delays.append(tempdelay- t0[ind])\n",
    "\n",
    "delays = np.array(delays)\n",
    "data_raw = np.array(data_raw)\n",
    "\n",
    "#create my own average time delay with n steps per picosecond and calculate the average value for plotting\n",
    "n_subticks = int(4)\n",
    "plotDelay = np.linspace(-1e4, 3e4, 40*n_subticks)\n",
    "plotData = np.zeros((len(wav_vec), len(plotDelay)))\n",
    "\n",
    "for indWav in range(len(wav_vec)):\n",
    "    '''\n",
    "    for indDelay in range(len(plotDelay)):\n",
    "        delay_boolArray = (delays[indWav,:] > plotDelay[indDelay]) & (delays[indWav,:] < plotDelay[indDelay] + 1e3/(n_subticks))\n",
    "        #print(delay_boolArray)\n",
    "        plotData[indWav,indDelay] = np.mean(data_raw[indWav, delay_boolArray], axis = None)\n",
    "    '''\n",
    "    #interpolate instead\n",
    "    plotData[indWav, :] = np.interp(plotDelay, delays[indWav,:],data_raw[indWav, :])\n",
    "\n",
    "\n",
    "#print(data_raw)\n",
    "plotData = plotData/np.max(abs(plotData))\n",
    "delayGrid, wavGrid = np.meshgrid(plotDelay, np.arange(0,len(wav_vec), 1))\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=plotHelperLatex.figSizer(1), dpi=288)\n",
    "map = ax.pcolor(delayGrid*1e-3, wavGrid, plotData, cmap=\"bwr\", clim=(-1,+1))\n",
    "#check out pcolormesh\n",
    "#map = ax.pcolormesh(delayGrid*1e-3, wavGrid, plotData, cmap=\"bwr\", clim=(-1,+1), shading =\"gouraud\")\n",
    "fig.colorbar(map, ax = ax, label=r\"relative $\\Delta A$ / a.u.\")\n",
    "ax.set_yticks(np.arange(0,len(wav_vec), 1), wav_vec)\n",
    "ax.set_ylabel('probe wavelength / nm')\n",
    "ax.set_xlabel('delay / ps')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shows the fit with the delay scan for a wavelength\n",
    "import json\n",
    "import fileParsingMethods\n",
    "import SeriesDegradation\n",
    "import plotHelperLatex\n",
    "plotHelperLatex.setMatplotSettings()\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import sys \n",
    "sys.path.insert(1, r\"C:\\Users\\M\\Documents\\phdmatlab\\sqib-pmma-probe-wavelength\\UV_Setup\\new_parallel_pol_pump653nm\")\n",
    "import ExponentialFunctions\n",
    "#493 nm\n",
    "#saturation file\n",
    "data_file = r\"C:\\Users\\M\\Documents\\phdmatlab\\sqib-pmma-probe-wavelength\\UV_Setup\\new_parallel_pol_pump653nm\\STD-493\\saturation_2024-01-19_14-24.mat\"\n",
    "#fit file\n",
    "fitJSON = r\"C:\\Users\\M\\Documents\\phdmatlab\\sqib-pmma-probe-wavelength\\UV_Setup\\new_parallel_pol_pump653nm\\STD-493\\TAfitPump653Probe493_DecayCorrected.JSON\"\n",
    "pRatio = 1502/1575\n",
    "dOD, delay, _ = fileParsingMethods.parseSummaryFileToArray(data_file, absorbance=True, backgroundLen=25)\n",
    "print(np.shape(dOD))\n",
    "times = fileParsingMethods.parseTime(fileParsingMethods.getTimes(data_file))\n",
    "correctionFactors = SeriesDegradation.degradationCompensation(14100, times, decaysteps=len(delay))\n",
    "\n",
    "fitData = json.load(open(fitJSON))[\"entries\"][0]\n",
    "t_data = np.linspace(delay[0], delay[-1], 1000)\n",
    "fitData = fitData['startParameters']\n",
    "position = fitData[0]['position']\n",
    "slope = fitData[0]['slope']\n",
    "amplitudes = []\n",
    "decays = []\n",
    "for i in range(len(fitData)-1):\n",
    "    amplitudes.append(fitData[i+1]['amplitude'])\n",
    "    decays.append(fitData[i+1]['decay'])\n",
    "amplitudes = np.array(amplitudes)\n",
    "decays = np.array(decays)\n",
    "y_data = ExponentialFunctions.universalExponentialEnumerable(t_data, position, slope, amplitudes, decays)\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=plotHelperLatex.figSizer(1,2.5), dpi=288)\n",
    "#ax.plot(delay*1e-3, np.mean(dOD, axis=0))\n",
    "print(np.shape(delay))\n",
    "ax.plot(delay*1e-3, np.mean(dOD*correctionFactors, axis=0), label = \"data\")\n",
    "ax.plot(t_data*1e-3,y_data, linestyle=\"--\", label=\"fit\")\n",
    "ax.set_ylabel(r'$\\Delta A$ / mOD')\n",
    "ax.set_xlabel(r't / ps')\n",
    "ax.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anisotropy 440"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#like example fit, but comparison of 440 orthogonal and parallel\n",
    "import json\n",
    "import fileParsingMethods\n",
    "import SeriesDegradation\n",
    "import plotHelperLatex\n",
    "plotHelperLatex.setMatplotSettings()\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import sys \n",
    "sys.path.insert(1, r\"C:\\Users\\M\\Documents\\phdmatlab\\sqib-pmma-probe-wavelength\\UV_Setup\\new_parallel_pol_pump653nm\")\n",
    "import ExponentialFunctions\n",
    "#440 nm\n",
    "#parallel\n",
    "#saturation file\n",
    "data_fileParallel = r\"C:\\Users\\M\\Documents\\phdmatlab\\sqib-pmma-probe-wavelength\\UV_Setup\\new_parallel_pol_pump653nm\\SHG-440\\saturation_2024-01-16_19-07.mat\"\n",
    "#fit file\n",
    "fitJSON_Parallel = r\"C:\\Users\\M\\Documents\\phdmatlab\\sqib-pmma-probe-wavelength\\UV_Setup\\new_parallel_pol_pump653nm\\SHG-440\\TAfitPump653Probe440_DecayCorrected.JSON\"\n",
    "pRatioParallel = 1489/1575\n",
    "dOD_parallel, delay_parallel, _ = fileParsingMethods.parseSummaryFileToArray(data_fileParallel, absorbance=True, backgroundLen=30)\n",
    "timesParallel = fileParsingMethods.parseTime(fileParsingMethods.getTimes(data_fileParallel))\n",
    "correctionFactorsParallel = SeriesDegradation.degradationCompensation(12600, timesParallel, decaysteps=len(delay_parallel), powerDensities=pRatioParallel)\n",
    "\n",
    "fitDataPar = json.load(open(fitJSON_Parallel))[\"entries\"][0]\n",
    "t_dataPar = np.linspace(delay_parallel[0], delay_parallel[-1], 1000)\n",
    "fitDataPar = fitDataPar['startParameters']\n",
    "positionPar = fitDataPar[0]['position']\n",
    "slopePar = fitDataPar[0]['slope']\n",
    "amplitudesPar = []\n",
    "decaysPar = []\n",
    "for i in range(len(fitDataPar)-1):\n",
    "    amplitudesPar.append(fitDataPar[i+1]['amplitude'])\n",
    "    decaysPar.append(fitDataPar[i+1]['decay'])\n",
    "amplitudesPar = np.array(amplitudesPar)\n",
    "decaysPar = np.array(decaysPar)\n",
    "\n",
    "#orthogonal\n",
    "#saturation file\n",
    "data_fileOrth = r\"C:\\Users\\M\\Documents\\phdmatlab\\sqib-pmma-probe-wavelength\\UV_Setup\\new_parallel_pol_pump653nm\\SHG-440\\Orthogonal\\saturation_2024-01-16_16-59.mat\"\n",
    "#fit file\n",
    "fitJSON_Orth = r\"C:\\Users\\M\\Documents\\phdmatlab\\sqib-pmma-probe-wavelength\\UV_Setup\\new_parallel_pol_pump653nm\\SHG-440\\Orthogonal\\TAfitPump653Probe440OrthPol_DecayCorrected.JSON\"\n",
    "pRatioOrth = 1523/1575\n",
    "dOD_orth, delay_orth, _ = fileParsingMethods.parseSummaryFileToArray(data_fileOrth, absorbance=True, backgroundLen=30)\n",
    "timesOrth = fileParsingMethods.parseTime(fileParsingMethods.getTimes(data_fileOrth))\n",
    "correctionFactorsOrth = SeriesDegradation.degradationCompensation(12600, timesOrth, decaysteps=len(delay_orth), powerDensities=pRatioOrth)\n",
    "\n",
    "fitDataOrth = json.load(open(fitJSON_Orth))[\"entries\"][0]\n",
    "t_dataOrth = np.linspace(delay_orth[0], delay_orth[-1], 1000)\n",
    "fitDataOrth = fitDataOrth['startParameters']\n",
    "positionOrth = fitDataOrth[0]['position']\n",
    "slopeOrth = fitDataOrth[0]['slope']\n",
    "amplitudesOrth = []\n",
    "decaysOrth = []\n",
    "for i in range(len(fitDataOrth)-1):\n",
    "    amplitudesOrth.append(fitDataOrth[i+1]['amplitude'])\n",
    "    decaysOrth.append(fitDataOrth[i+1]['decay'])\n",
    "amplitudesOrth = np.array(amplitudesOrth)\n",
    "decaysOrth = np.array(decaysOrth)\n",
    "#y_data = ExponentialFunctions.universalExponentialEnumerable(t_data, position, slope, amplitudes, decays)\n",
    "\n",
    "\n",
    "\n",
    "#let me try to do the perrin formula\n",
    "r_anisotropy = lambda par, orth: (par-orth)/(par+2*orth)\n",
    "\n",
    "#stitch together parallel and orth to be on the same delay setting\n",
    "#taken from raw data plot above\n",
    "#create my own average time delay with n steps per picosecond and calculate the average value for plotting\n",
    "n_subticks = int(1)\n",
    "plotDelay = np.linspace(-2e4, 4e4, 30*n_subticks)\n",
    "plotData = np.zeros((2, len(plotDelay)))\n",
    "\n",
    "correctedParallel = np.mean(dOD_parallel*correctionFactorsParallel, axis=0)\n",
    "correctedOrth = np.mean(dOD_orth*correctionFactorsOrth, axis=0)\n",
    "\n",
    "for indDelay in range(len(plotDelay)):\n",
    "    delay_boolArray = (delay_orth[:]-positionOrth > plotDelay[indDelay]) & (delay_orth[:]-positionOrth < plotDelay[indDelay] + 1e3/(n_subticks))\n",
    "    plotData[0,indDelay] = np.mean(correctedOrth[delay_boolArray], axis = None)\n",
    "for indDelay in range(len(plotDelay)):\n",
    "    delay_boolArray = (delay_parallel[:]-positionPar > plotDelay[indDelay]) & (delay_parallel[:]-positionPar < plotDelay[indDelay] + 1e3/(n_subticks))\n",
    "    plotData[1,indDelay] = np.mean(correctedParallel[delay_boolArray], axis = None)\n",
    "\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=plotHelperLatex.figSizer(2,2.5), dpi=288)\n",
    "#ax.plot(delay*1e-3, np.mean(dOD, axis=0))\n",
    "#ax.plot(delay_parallel*1e-3-positionPar*1e-3, correctedParallel, color = \"r\", label=\"parallel\")\n",
    "ax.plot(plotDelay*1e-3, plotData[1], color=\"r\", linestyle=\"dotted\", label=\"parallel\")\n",
    "#ax.plot(delay_orth*1e-3-positionOrth*1e-3, correctedOrth*2, color = \"b\", label=r\"2 $\\times$ orthogonal\")\n",
    "ax.plot(plotDelay*1e-3, plotData[0]*2, color = \"b\", linestyle=\"dotted\", label=r\"2 $\\times$ orthogonal\")\n",
    "ax.set_xlim((-25, 40))\n",
    "#ax.plot(t_data*1e-3,y_data, linestyle=\"--\")\n",
    "ax.set_ylabel(r'$\\Delta A$ / mOD')\n",
    "ax.set_xlabel(r'delay / ps')\n",
    "ax.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "fig2, ax2 = plt.subplots(1,1, figsize=plotHelperLatex.figSizer(2,2.5), dpi=288)\n",
    "#plt.plot(plotDelay, plotData[0,:])\n",
    "#plt.plot(plotDelay, plotData[1,:])\n",
    "ax2.plot(plotDelay*1e-3, r_anisotropy(plotData[1], plotData[0]))\n",
    "ax2.set_ylim((0,0.5))\n",
    "ax2.set_xlim((0,30))\n",
    "ax2.set_ylabel('r anisotropy / 1')\n",
    "ax2.set_xlabel('delay / ps')\n",
    "ax2.set_yticks([0, 0.25, 0.4, 0.5])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot delay scans of 493 and 680 nm\n",
    "import plotHelperLatex\n",
    "plotHelperLatex.setMatplotSettings()\n",
    "import sys\n",
    "sys.path.insert(1, r\"C:\\Users\\M\\Documents\\phdmatlab\\sqib-pmma-probe-wavelength\\UV_Setup\\new_parallel_pol_pump653nm\")\n",
    "import ShowDelayScan\n",
    "#493 nm\n",
    "ShowDelayScan.fromFiles(r\"C:\\Users\\M\\Documents\\phdmatlab\\sqib-pmma-probe-wavelength\\UV_Setup\\new_parallel_pol_pump653nm\\STD-493\\saturation_2024-01-19_14-24.mat\", fig_size = plotHelperLatex.figSizer(1,4), showMean=False)\n",
    "#680 nm\n",
    "ShowDelayScan.fromFiles(r\"C:\\Users\\M\\Documents\\phdmatlab\\sqib-pmma-probe-wavelength\\UV_Setup\\new_parallel_pol_pump653nm\\STD-680\\saturation_2024-01-16_14-09.mat\", fig_size = plotHelperLatex.figSizer(1,4), showMean=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### peak radiance variation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import constants as const\n",
    "from scipy import io\n",
    "import numpy as np\n",
    "import json\n",
    "from fileParsingMethods import numberFileGenerator\n",
    "\n",
    "import plotHelperLatex\n",
    "plotHelperLatex.setMatplotSettings()\n",
    "\n",
    "#From 2023.12.22 PumpPowerVar in pump 653 Probe 680\n",
    "#2nd-x;170.98460380387596;4.882207633023595;1.0;0.0;3.5228\n",
    "#2nd-x Error;0.044586461622659335;0.10565856496080137;60.88881374774401;1.876611874015875;3.5228\n",
    "#2nd-y;123.76193757659699;5.398671742339542;1.0;0.0;3.5228\n",
    "#2nd-y Error;0.007988920725724555;0.018944810621290376;10.67173147785706;0.31277821947196766;3.5228\n",
    "\n",
    "file = open(r\"c:\\Users\\M\\Documents\\phdmatlab\\sqib-pmma-probe-wavelength\\UV_Setup\\new_parallel_pol_pump653nm\\STD-680\\2023.12.22_PumpPowerVar\\TAfitPump653Probe680_OUTPUT.JSON\")\n",
    "entries = json.load(file)['entries']\n",
    "entries_files = []\n",
    "dOD = []\n",
    "for entry in entries:\n",
    "    entries_files.append(entry['inputFile'])\n",
    "    dOD.append([entry['popt'][2], np.sqrt(entry['pcov'][2][2])])\n",
    "\n",
    "dOD = np.array(dOD)\n",
    "dOD[dOD == np.inf] = np.NaN\n",
    "#print(dOD)\n",
    "#these are in order\n",
    "pumpRad = np.array([[610, 45], [610, 45], [610, 45], [3195, 142], [4357,172], [5810, 269], [4358, 230], [4358, 230], [4358, 230]])\n",
    "probeRad = np.array([[916, 100], [1831, 106], [458, 50], [458, 50], [458, 50], [458, 50], [916, 53], [3663, 74], [1831, 60]])\n",
    "\n",
    "\n",
    "#try calculating a fun correction factor based on the first 3 measurements that have identical pump radiance\n",
    "#need to take the times such as done in degradation\n",
    "io.loadmat(r\"C:\\Users\\M\\Documents\\phdmatlab\\sqib-pmma-probe-wavelength\\UV_Setup\\new_parallel_pol_pump653nm\\STD-680\\2023.12.22_PumpPowerVar\\saturation_2023-12-22_11-47.mat\")\n",
    "#print(np.polyfit(pumpRad[2:6,0], dOD[2:6,0], 1, cov=True))\n",
    "linParameter = np.polyfit(pumpRad[2:5,0], dOD[2:5,0], 1)\n",
    "#print(pumpRad[])\n",
    "#Plot first 6 points as they should have relatively little sample degradation, because of their order and the pump power\n",
    "fig, ax1 = plt.subplots(1,1, figsize=plotHelperLatex.figSizer(2,2.6/2), dpi = 288)\n",
    "fig2, ax2 = plt.subplots(1,1, figsize=plotHelperLatex.figSizer(2,2.6/2), dpi = 288)\n",
    "#plt.tight_layout()\n",
    "#ax1.plot(pumpRad[:6,0], dOD[:6,0], 'b.')\n",
    "#yerror of dOD fitting is not sensible\n",
    "ax1.plot(pumpRad[(0,5),0]/2e5, np.polyval(linParameter, pumpRad[(0,5),0]), 'royalblue', linestyle=\"dashed\")\n",
    "ax1.errorbar(pumpRad[:6,0]/2e5, dOD[:6,0], xerr = pumpRad[:6,1]/2e5, ls = \"None\", ecolor = 'b', capsize = 2)\n",
    "\n",
    "ax1.set_xlabel(r'pump radiant exposure $H_{x_0,y_0}$ / $\\mathrm{\\frac{J}{m^2}}$')\n",
    "ax1.set_ylabel(r'$\\Delta A$ / mOD')\n",
    "ax1.set_ylim([0,-2.2])\n",
    "#ax2.plot(probeRad[6:,0], dOD[6:,0], 'b')\n",
    "ax2.errorbar(probeRad[6:,0]/4e5, dOD[6:,0], xerr = probeRad[6:,1]/4e5, yerr=abs(dOD[6:,0]*pumpRad[6:,1]/pumpRad[6:,0]), ls=\"None\", ecolor = \"b\", capsize = 2)\n",
    "ax2.set_xlabel(r'probe radiant exposure $H_{x_0,y_0}$ / $\\mathrm{\\frac{J}{m^2}}$')\n",
    "ax2.set_ylabel(r'$\\Delta A$ / mOD')\n",
    "\n",
    "\n",
    "#including degradation\n",
    "import SeriesDegradation\n",
    "dirPath = r\"C:\\Users\\M\\Documents\\phdmatlab\\sqib-pmma-probe-wavelength\\UV_Setup\\new_parallel_pol_pump653nm\\STD-680\\2023.12.22_PumpPowerVar\"\n",
    "filePaths = []\n",
    "start = 6615\n",
    "stop = 6620\n",
    "filePaths += numberFileGenerator(start, stop)\n",
    "start = 6630\n",
    "stop = 6632\n",
    "filePaths += numberFileGenerator(start, stop)\n",
    "start = 6636\n",
    "stop = 6644\n",
    "filePaths += numberFileGenerator(start, stop)\n",
    "\n",
    "p_ratio = 590/1575\n",
    "powerDensitiesIn = [1.05 for i in range(6)]\n",
    "powerDensitiesIn = np.concatenate((powerDensitiesIn, [5.5 for i in range(3)][:]), axis = None)\n",
    "powerDensitiesIn = np.concatenate((powerDensitiesIn, [7.5 for i in range(3)][:]), axis = None)\n",
    "powerDensitiesIn = np.concatenate((powerDensitiesIn, [10 for i in range(3)][:]), axis = None)\n",
    "powerDensitiesIn = np.array(powerDensitiesIn)*p_ratio\n",
    "timesPump = SeriesDegradation.getTimes(filePaths, dirPath)\n",
    "\n",
    "\n",
    "#get delta t of times\n",
    "timesFromZeroPump = SeriesDegradation.parseTime(timesPump)\n",
    "CorrectionEstimatedPump = SeriesDegradation.degradationCompensation(14100, timesFromZeroPump, 1, powerDensities=powerDensitiesIn)\n",
    "\n",
    "corr_dODpumpVar = dOD[:6,0][:]*CorrectionEstimatedPump[1:-1:3].T\n",
    "corr_dODpumpVar = corr_dODpumpVar[0]\n",
    "ax1.plot(pumpRad[:6,0]/2e5, corr_dODpumpVar, \"r.\", linestyle=\"None\")\n",
    "pumpVar_corrFit = np.polyfit(pumpRad[:6,0], corr_dODpumpVar, deg = 2)\n",
    "ax1.plot(pumpRad[[0,5],0]/2e5, np.polyval(pumpVar_corrFit, pumpRad[[0,5],0]), \"orange\", linestyle=\"dashed\")\n",
    "### Probe power var\n",
    "filePaths = []\n",
    "start = 6645\n",
    "stop = 6653\n",
    "filePaths += numberFileGenerator(start, stop)\n",
    "\n",
    "timesProbe = SeriesDegradation.getTimes(filePaths, dirPath)\n",
    "#get delta t of times\n",
    "timesFromZeroProbe = SeriesDegradation.parseTime(timesProbe)\n",
    "CorrectionEstimatedProbe = SeriesDegradation.degradationCompensation(12600, timesFromZeroProbe, 1, powerDensities=7.5*p_ratio)\n",
    "corr_dODprobeVar = dOD[6:,0][:]*CorrectionEstimatedProbe[1:-1:3].T\n",
    "corr_dODprobeVar = corr_dODprobeVar[0]\n",
    "#ax2.plot(probeRad[6:,0], corr_dODprobeVar, 'r.', linestyle=\"None\")\n",
    "ax2.errorbar(probeRad[6:,0]/4e5, corr_dODprobeVar, yerr = abs(corr_dODprobeVar*pumpRad[6:,1]/pumpRad[6:,0]), xerr = probeRad[6:,1]/4e5, linestyle=\"None\", capsize=2, ecolor=\"r\")\n",
    "ticks = [2e-3,  4e-3, 6e-3, 8e-3, 10e-3]\n",
    "ax2.set_xticks(ticks, [\"2e-3\", \"4e-3\", \"6e-3\", \"8e-3\", \"10e-3\"])\n",
    "#fig.suptitle('no degradation correction yet')\n",
    "\n",
    "#custom legend\n",
    "from matplotlib.lines import Line2D\n",
    "legend_items = [Line2D([0], [0], color = \"blue\", label=\"raw data\", marker=\"s\", linestyle=\"None\"),\n",
    "                Line2D([0], [0], color = \"red\", label=\"corrected\", marker=\"s\", linestyle=\"None\"),\n",
    "                Line2D([0], [0], color = \"black\", label=\"linear fit\", marker=\"None\",linestyle=\"dashed\")]\n",
    "#for ind in range(len(times)):\n",
    "#    legend_items.append(Line2D([0], [0], color = colors[ind], label=\"%.1f ps\" %(times[ind]*1e-3), marker=\"s\", linestyle=\"None\"))\n",
    "\n",
    "ax1.legend(handles=legend_items)\n",
    "ax2.legend(handles=legend_items[:2])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import plotHelperLatex\n",
    "plotHelperLatex.setMatplotSettings()\n",
    "sys.path.insert(1, r\"C:\\Users\\M\\Documents\\phdmatlab\\sqib-pmma-probe-wavelength\\UV_Setup\\new_parallel_pol_pump653nm\")\n",
    "from ShowDelayScan import fromFiles\n",
    "\n",
    "#this is the constant pump power and probe power variation\n",
    "filenames=[]\n",
    "for x in range(6645,6654,1):\n",
    "    filenames.append(\"\\TA_fourier_%4d\" %(x))\n",
    "dirPath = r\"C:\\Users\\M\\Documents\\phdmatlab\\sqib-pmma-probe-wavelength\\UV_Setup\\new_parallel_pol_pump653nm\\STD-680\\2023.12.22_PumpPowerVar\"\n",
    "fromFiles(filenames, dirPath, plotHelperLatex.figSizer(2), False)\n",
    "\n",
    "filenames=[]\n",
    "for x in range(6615,6621,1):\n",
    "    filenames.append(\"\\TA_fourier_%4d\" %(x))\n",
    "for x in range(6630,6633,1):\n",
    "    filenames.append(\"\\TA_fourier_%4d\" %(x))\n",
    "fromFiles(filenames, dirPath, plotHelperLatex.figSizer(2), False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Degradation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import constants as const\n",
    "from scipy import io \n",
    "import os\n",
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "import json\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "import plotHelperLatex\n",
    "plotHelperLatex.setMatplotSettings()\n",
    "import SeriesDegradation\n",
    "\n",
    "    \n",
    "\n",
    "testArray = [r\"C:\\Users\\M\\Documents\\phdmatlab\\sqib-pmma-probe-wavelength\\UV_Setup\\new_parallel_pol_pump653nm\\Pump653Probe493_Degradation\\TA_fourier_6778.mat\", \n",
    "             r\"C:\\Users\\M\\Documents\\phdmatlab\\sqib-pmma-probe-wavelength\\UV_Setup\\new_parallel_pol_pump653nm\\Pump653Probe493_Degradation\\TA_fourier_6779.mat\"]\n",
    "\n",
    "#to be tested yet\n",
    "dArray, delay, _ = SeriesDegradation.parseSummaryFileToArray(r\"C:\\Users\\M\\Documents\\phdmatlab\\sqib-pmma-probe-wavelength\\UV_Setup\\new_parallel_pol_pump653nm\\Pump653Probe493_Degradation\\saturation_2024-01-19_16-14.mat\")\n",
    "\n",
    "\n",
    "#powerVar = pd.read_excel(\"CorrectedPump653ProbeWavelengthScan_UV-extended.xlsx\", sheet_name='Degradation493nm')\n",
    "dtime = SeriesDegradation.getTimes(r\"C:\\Users\\M\\Documents\\phdmatlab\\sqib-pmma-probe-wavelength\\UV_Setup\\new_parallel_pol_pump653nm\\Pump653Probe493_Degradation\\saturation_2024-01-19_16-14.mat\")\n",
    "dtime = SeriesDegradation.parseTime(dtime)\n",
    "#dOD = powerVar['dOD / mOD']\n",
    "\n",
    "dArray, aArray, _ = SeriesDegradation.removeBackground(dArray, 20)\n",
    "\n",
    "t0_estimate = np.argmax((aArray[0,1:]-aArray[0,:-1])/(delay[1:]-delay[:-1]))\n",
    "print(t0_estimate)\n",
    "popt, pcov = SeriesDegradation.fitDegradation(aArray, dtime, t0=t0_estimate)\n",
    "\n",
    "print(popt)\n",
    "print(np.sqrt(pcov))\n",
    "\n",
    "\n",
    "timeAt = np.array([0,1e3,5e3]) #fs\n",
    "\n",
    "\n",
    "Corr = SeriesDegradation.degradationCompensation(popt, dtime, np.shape(aArray)[1])\n",
    "fig, ax = plt.subplots(1,1, figsize=plotHelperLatex.figSizer(1,3), dpi = 288)\n",
    "for i in range(len(timeAt)):\n",
    "    ax.plot(dtime, aArray[:,i], label=\"delay = %.1f ps\" %(timeAt[i]*1e-3))\n",
    "    ax.plot(dtime, aArray[:,i]*Corr[:,i])\n",
    "#ax.plot(dtime, dOD[0,2]-dtime*popt)\n",
    "ax.legend()\n",
    "ax.set_xlabel('time / s')\n",
    "ax.set_ylabel(r'$\\Delta A$ / mOD')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import SeriesDegradation\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import plotHelperLatex\n",
    "plotHelperLatex.setMatplotSettings()\n",
    "\n",
    "\n",
    "def numberFileGenerator(start, stop, namePrefix=r\"TA_fourier_\", nameSuffix=r\"\"):\n",
    "    ''''generate TA_fourier_02364 style names in list form'''\n",
    "    vec = np.arange(start, stop+1,1)\n",
    "    filenames = []\n",
    "    for number in vec:\n",
    "        filenames.append(namePrefix + str(number)+ nameSuffix)\n",
    "    return filenames\n",
    "\n",
    "\n",
    "start = 6778\n",
    "stop = 6787\n",
    "dirPath = r\"C:\\Users\\M\\Documents\\phdmatlab\\sqib-pmma-probe-wavelength\\UV_Setup\\new_parallel_pol_pump653nm\\Pump653Probe493_Degradation\"\n",
    "\n",
    "\n",
    "#got to fix the input to the changed plotTrend function\n",
    "SeriesDegradation.plotTrend(numberFileGenerator(start, stop), dirPath, plotHelperLatex.figSizer(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import SeriesDegradation\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import plotHelperLatex\n",
    "plotHelperLatex.setMatplotSettings()\n",
    "import fileParsingMethods\n",
    "import sys\n",
    "sys.path.insert(1, r\"C:\\Users\\M\\Documents\\phdmatlab\\sqib-pmma-probe-wavelength\\UV_Setup\\new_parallel_pol_pump653nm\")\n",
    "import ShowDelayScan\n",
    "\n",
    "#need to switch getTimes to the same system as parseSummary to allow any type of input\n",
    "if True:\n",
    "    start = 6778\n",
    "    stop = 6787\n",
    "    dirPath = r\"C:\\Users\\M\\Documents\\phdmatlab\\sqib-pmma-probe-wavelength\\UV_Setup\\new_parallel_pol_pump653nm\\Pump653Probe493_Degradation\"\n",
    "else:\n",
    "    start = 6645\n",
    "    stop = 6653\n",
    "    dirPath = r\"C:\\Users\\M\\Documents\\phdmatlab\\sqib-pmma-probe-wavelength\\UV_Setup\\new_parallel_pol_pump653nm\\STD-680\\2023.12.22_PumpPowerVar\"\n",
    "\n",
    "\n",
    "filePaths = fileParsingMethods.numberFileGenerator(start, stop)\n",
    "print(len(filePaths))\n",
    "times = SeriesDegradation.getTimes(filePaths, dirPath)\n",
    "dArray, delay,_ = SeriesDegradation.parseSummaryFileToArray(filePaths, dirPath)\n",
    "_, aArray, _ = SeriesDegradation.removeBackground(dArray, 20)\n",
    "#get delta t of times\n",
    "timesFromZero = np.array(SeriesDegradation.parseTime(times),dtype=int)\n",
    "\n",
    "fig2, ax2 = plt.subplots(1,1, figsize=plotHelperLatex.figSizer(2.5), dpi = 288)\n",
    "fig3, ax3 = plt.subplots(1,1, figsize=plotHelperLatex.figSizer(2.5), dpi = 288)\n",
    "for ind in range(np.shape(aArray)[0]):\n",
    "    ax2.plot(delay*1e-3, aArray[ind])\n",
    "\n",
    "#estimate t0 by finding maximum value in aArray\n",
    "t0_estimate = np.argmax((aArray[0,1:]-aArray[0,:-1])/(delay[1:]-delay[:-1]))\n",
    "print(t0_estimate)\n",
    "popt, pcov = SeriesDegradation.fitDegradation(aArray, timesFromZero, t0 = t0_estimate+2, sliding_window_len=5)\n",
    "print(popt)\n",
    "print(np.sqrt(pcov))\n",
    "\n",
    "Correction = SeriesDegradation.degradationCompensation(popt, timesFromZero, np.shape(aArray)[1], powerDensities=1)\n",
    "#Correction = SeriesDegradation.degradationCompensation(14000, timesFromZero, np.shape(aArray)[1], powerDensities=2.8)\n",
    "CorrArray = np.zeros(np.shape(aArray))\n",
    "for ind in range(np.shape(aArray)[0]):\n",
    "    CorrArray[ind,:] = aArray[ind,:]*Correction[ind,:]\n",
    "print(np.shape(aArray))\n",
    "#timesFromZero = np.append(timesFromZero, np.mean(timesFromZero[1:]-timesFromZero[:-1], axis = None))\n",
    "delays, measurementTimes = np.meshgrid(delay, timesFromZero)\n",
    "fig, ax = plt.subplots(1,1, figsize=(8,4), dpi = 288)\n",
    "map = ax.pcolor(delays*1e-3, measurementTimes, CorrArray, cmap=\"plasma\", snap=False)\n",
    "ax.set_xlabel('delay time / ps')\n",
    "ax.set_ylabel('total time elapsed at start / s')\n",
    "fig.colorbar(map, ax=ax, label=r\"$\\Delta A$ / a.u.\")\n",
    "ax.set_yticks(timesFromZero-np.mean(timesFromZero[1]-timesFromZero[0], axis=None)/2, timesFromZero)\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "for ind in range(np.shape(aArray)[0]):\n",
    "    ax3.plot(delay*1e-3, CorrArray[ind])\n",
    "#ax2.set_xlim([-5, 50])\n",
    "#ax3.set_xlim([-5, 50])\n",
    "#ax2.set_ylim([0.3,0.8])\n",
    "#ax3.set_ylim([0.3,0.8])\n",
    "ax2.set_xlabel('delay time / ps')\n",
    "ax2.set_ylabel(r'$\\Delta A$ / mOD')\n",
    "ax3.set_xlabel('delay time / ps')\n",
    "ax3.set_ylabel(r'$\\Delta A$ / mOD')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#doing a comparison of powervar here\n",
    "import SeriesDegradation\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import plotHelperLatex\n",
    "plotHelperLatex.setMatplotSettings()\n",
    "import ShowDelayScan\n",
    "from fileParsingMethods import numberFileGenerator\n",
    "\n",
    "\n",
    "start = 6645\n",
    "stop = 6653\n",
    "dirPath = r\"C:\\Users\\M\\Documents\\phdmatlab\\sqib-pmma-probe-wavelength\\UV_Setup\\new_parallel_pol_pump653nm\\STD-680\\2023.12.22_PumpPowerVar\"\n",
    "\n",
    "\n",
    "filePaths = numberFileGenerator(start, stop)\n",
    "times = SeriesDegradation.getTimes(filePaths, dirPath)\n",
    "dArray, delay, _ = SeriesDegradation.parseSummaryFileToArray(filePaths, dirPath)\n",
    "_, aArray, _ = SeriesDegradation.removeBackground(dArray, 10)\n",
    "#get delta t of times\n",
    "timesFromZero = SeriesDegradation.parseTime(times)\n",
    "fig1, ax1 = plt.subplots(1,1, figsize=plotHelperLatex.figSizer(3.2), dpi = 288)\n",
    "fig2, ax2 = plt.subplots(1,1, figsize=plotHelperLatex.figSizer(3.2), dpi = 288)\n",
    "fig3, ax3 = plt.subplots(1,1, figsize=plotHelperLatex.figSizer(3.2), dpi = 288)\n",
    "for ind in range(np.shape(aArray)[0]):\n",
    "    ax2.plot(delay*1e-3, aArray[ind])\n",
    "\n",
    "#estimate t0 by finding maximum value in aArray\n",
    "t0_estimate = np.argmax((aArray[0,1:]-aArray[0,:-1])/(delay[1:]-delay[:-1]))\n",
    "print(t0_estimate)\n",
    "popt, pcov = SeriesDegradation.fitDegradation(aArray, timesFromZero, t0 = t0_estimate+5, sliding_window_len=5)\n",
    "print(popt)\n",
    "print(np.sqrt(pcov))\n",
    "refPowerDensity = 1575\n",
    "powDens680 = 581*7.5\n",
    "powDensRatio = powDens680/refPowerDensity\n",
    "\n",
    "CorrectionNative = SeriesDegradation.degradationCompensation(popt, timesFromZero, np.shape(aArray)[1], powerDensities=1)\n",
    "CorrectionEstimated = SeriesDegradation.degradationCompensation(12620, timesFromZero, np.shape(aArray)[1], powerDensities=powDensRatio)\n",
    "CorrArray = np.zeros(np.shape(aArray))\n",
    "for ind in range(np.shape(aArray)[0]):\n",
    "    ax1.plot(delay*1e-3, aArray[ind,:])\n",
    "    ax2.plot(delay*1e-3, aArray[ind,:]*CorrectionNative[ind,:])\n",
    "    ax3.plot(delay*1e-3, aArray[ind,:]*CorrectionEstimated[ind,:])\n",
    "\n",
    "\n",
    "#fig1.suptitle(\"raw\")\n",
    "#fig2.suptitle(\"Native\")\n",
    "#fig3.suptitle(\"Estimate\")\n",
    "ax1.set_xlabel('delay time / ps')\n",
    "ax1.set_ylabel(r'$\\Delta A$ / mOD')\n",
    "ax2.set_xlabel('delay time / ps')\n",
    "ax2.set_ylabel(r'$\\Delta A$ / mOD')\n",
    "ax3.set_xlabel('delay time / ps')\n",
    "ax3.set_ylabel(r'$\\Delta A$ / mOD')\n",
    "ax1.set_ylim((-1.2,-0.8))\n",
    "ax2.set_ylim((-1.2,-0.8))\n",
    "ax3.set_ylim((-1.2,-0.8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#doing a comparison of powervar here\n",
    "import SeriesDegradation\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import plotHelperLatex\n",
    "plotHelperLatex.setMatplotSettings()\n",
    "import ShowDelayScan\n",
    "from fileParsingMethods import numberFileGenerator\n",
    "\n",
    "\n",
    "\n",
    "dirPath = r\"C:\\Users\\M\\Documents\\phdmatlab\\sqib-pmma-probe-wavelength\\UV_Setup\\new_parallel_pol_pump653nm\\STD-680\\2023.12.22_PumpPowerVar\"\n",
    "filePaths = []\n",
    "start = 6615\n",
    "stop = 6620\n",
    "filePaths += numberFileGenerator(start, stop)\n",
    "start = 6630\n",
    "stop = 6632\n",
    "filePaths += numberFileGenerator(start, stop)\n",
    "start = 6636\n",
    "stop = 6644\n",
    "filePaths += numberFileGenerator(start, stop)\n",
    "\n",
    "p_ratio = 590/1580\n",
    "powerDensitiesIn = [1.05 for i in range(6)]\n",
    "powerDensitiesIn = np.concatenate((powerDensitiesIn, [5.5 for i in range(3)][:]), axis = None)\n",
    "powerDensitiesIn = np.concatenate((powerDensitiesIn, [7.5 for i in range(3)][:]), axis = None)\n",
    "powerDensitiesIn = np.concatenate((powerDensitiesIn, [10 for i in range(3)][:]), axis = None)\n",
    "powerDensitiesIn = np.array(powerDensitiesIn)*p_ratio\n",
    "times = SeriesDegradation.getTimes(filePaths, dirPath)\n",
    "dArray, delay, _ = SeriesDegradation.parseSummaryFileToArray(filePaths, dirPath)\n",
    "_, aArray, _ = SeriesDegradation.removeBackground(dArray, 10)\n",
    "\n",
    "#get delta t of times\n",
    "timesFromZero = SeriesDegradation.parseTime(times)\n",
    "fig1, ax1 = plt.subplots(1,1, figsize=plotHelperLatex.figSizer(2), dpi = 288)\n",
    "#fig2, ax2 = plt.subplots(1,1, figsize=plotHelperLatex.figSizer(3.2), dpi = 144)\n",
    "#fig3, ax3 = plt.subplots(1,1, figsize=plotHelperLatex.figSizer(3.2), dpi = 144)\n",
    "\n",
    "\n",
    "#estimate t0 by finding maximum value in aArray\n",
    "t0_estimate = np.argmax((aArray[0,1:]-aArray[0,:-1])/(delay[1:]-delay[:-1]))\n",
    "print(t0_estimate)\n",
    "#popt, pcov = SeriesDegradation.fitDegradation(aArray, timesFromZero, t0 = t0_estimate+2, sliding_window_len=5)\n",
    "#print(popt)\n",
    "#print(np.sqrt(pcov))\n",
    "\n",
    "\n",
    "CorrectionEstimated = SeriesDegradation.degradationCompensation(14100, timesFromZero, np.shape(aArray)[1], powerDensities=powerDensitiesIn)\n",
    "#CorrectionEstimated = SeriesDegradation.degradationCompensation(14100, timesFromZero, np.shape(aArray)[1], powerDensities=2.8)\n",
    "CorrArray = np.zeros(np.shape(aArray))\n",
    "for ind in range(np.shape(aArray)[0]):\n",
    "    ax1.plot(delay*1e-3, aArray[ind,:]*CorrectionEstimated[ind,:])\n",
    "    #ax2.plot(delay*1e-3, aArray[ind,:]*CorrectionNative[ind,:])\n",
    "    #ax3.plot(delay*1e-3, aArray[ind,:]*CorrectionEstimated[ind,:])\n",
    "\n",
    "\n",
    "#fig1.suptitle(\"raw\")\n",
    "#fig2.suptitle(\"Native\")\n",
    "#fig3.suptitle(\"Estimate\")\n",
    "ax1.set_xlabel('delay time / ps')\n",
    "ax1.set_ylabel(r'$\\Delta$OD / mOD')\n",
    "#ax2.set_xlabel('delay time / ps')\n",
    "#ax2.set_ylabel('dOD / mOD')\n",
    "#ax3.set_xlabel('delay time / ps')\n",
    "#ax3.set_ylabel('dOD / mOD')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correction value check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import constants as const\n",
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "import sys\n",
    "import json\n",
    "sys.path.insert(1, r\"C:\\Users\\M\\Documents\\phdmatlab\\sqib-pmma-probe-wavelength\\UV_Setup\\new_parallel_pol_pump653nm\")\n",
    "from peakRadianceAuto import autoPeakRadiance\n",
    "from ArtrayAnalysis import ArtFit\n",
    "import plotHelperLatex\n",
    "plotHelperLatex.setMatplotSettings()\n",
    "from matplotlib import ticker\n",
    "\n",
    "def correctionFactorWithError(pathJSON, fittingPath):\n",
    "    '''Returns correction factor with uncertainty in dOD per W/m^2\\\\\n",
    "        pathJSON is to summary\\\\\n",
    "            fittingPath is to standard fit.txt (2 beam pointspreads supported)'''\n",
    "    #don't care about loading these multiple times\n",
    "    #returns first \n",
    "    peakRad, dPeakRad = autoPeakRadiance(pathJSON, fittingPath)\n",
    "    #only choose pump\n",
    "    peakRad = peakRad[1]\n",
    "    dPeakRad = dPeakRad[1]\n",
    "    #dict with {\"pump/probe\": {\"x/y\" : [[sig, error],...]}}\n",
    "    dataDict = ArtFit.parseFitFile(fittingPath)\n",
    "\n",
    "    pump = dataDict[\"pump\"]\n",
    "    probe = dataDict[\"probe\"]\n",
    "    #coeffs = x_center, sig, Amplitude, offset\n",
    "    #sig1Error = lambda corr, sig1, sig2, muDiff, dsig1 : dsig1*corr*(sig1**3/sig2**2+sig1+muDiff**2*sig1/(sig1**2+sig2**2)**2)\n",
    "    #sig2Error = lambda corr, sig1, sig2, muDiff, dsig2: dsig2*corr*((sig1**2+sig2**2)/sig2 + muDiff**2*sig2/(sig1**2+sig2**2)**2)\n",
    "    #muDiffError = lambda corr, sig1, sig2, muDiff, dmuDiff: dmuDiff*corr*muDiff/(sig1**2+sig2**2)\n",
    "\n",
    "    sig1Error = lambda corr, coeffs1, coeffs2: coeffs1[1,1]*corr*(coeffs1[1,0]**3/coeffs2[1,0]**2+coeffs1[1,0]+(coeffs1[0,0]-coeffs2[0,0])**2*coeffs1[1,0]/(coeffs1[1,0]**2+coeffs2[1,0]**2)**2)\n",
    "    sig2Error = lambda corr, coeffs1, coeffs2: coeffs2[1,1]*corr*((coeffs1[1,0]**2+coeffs2[1,0]**2)/coeffs2[1,0]+ (coeffs1[0,0]-coeffs2[0,0])**2*coeffs2[1,0]/(coeffs1[1,0]**2+coeffs2[1,0]**2)**2)\n",
    "    #using compound error for this one\n",
    "    muDiffError = lambda corr, coeffs1, coeffs2: (coeffs1[0,1]+coeffs2[0,1])*corr*(coeffs1[0,0]-coeffs2[0,0])/(coeffs1[1,0]**2+coeffs2[1,0]**2)\n",
    "    #simplification\n",
    "    fullError = lambda corr, coeffs1, coeffs2: sig1Error(corr, coeffs1, coeffs2) + sig2Error(corr, coeffs1, coeffs2) + muDiffError(corr, coeffs1, coeffs2)\n",
    "    #takes pump then probe\n",
    "    xCorr = ArtFit.calculateOverlapCorrection(pump[\"x\"][:,0], probe[\"x\"][:,0], 5)\n",
    "    dXCorr = fullError(xCorr, pump['x'], probe['x'])\n",
    "    yCorr = ArtFit.calculateOverlapCorrection(pump[\"y\"][:,0], probe[\"y\"][:,0], 5)\n",
    "    dYCorr = fullError(xCorr, pump['y'], probe['y'])\n",
    "    Corr = [xCorr, yCorr]\n",
    "    totalCorr = xCorr*yCorr\n",
    "    totalError = (xCorr*dYCorr+yCorr*dXCorr)/peakRad + totalCorr*dPeakRad/peakRad**2\n",
    "    #print(totalCorr)\n",
    "    #print(totalError)\n",
    "    sigCalc = lambda probeCoeff, pumpCoeff: [probeCoeff[1,0]/pumpCoeff[1,0], probeCoeff[1,1]/pumpCoeff[1,0] + probeCoeff[1,0]/pumpCoeff[1,0]**2*pumpCoeff[1,1]]\n",
    "    sigbysig = np.array([sigCalc(probe['x'], pump['x']), sigCalc(probe['y'], pump['y'])], dtype = float)\n",
    "    dmu = np.array([[abs(probe[\"x\"][0,0]-pump[\"x\"][0,0]), probe[\"x\"][0,1]+pump[\"x\"][0,1]],[abs(probe[\"y\"][0,0]-pump[\"y\"][0,0]), probe[\"y\"][0,1]+pump[\"y\"][0,1]]], dtype = float)\n",
    "    return [Corr, totalError], sigbysig, dmu, pump, probe, peakRad\n",
    "\n",
    "def getNumericCorrection(summaryJSON):\n",
    "    f_JSON = open(summaryJSON, 'r')\n",
    "    summary_JSON = json.load(f_JSON)\n",
    "    f_JSON.close()\n",
    "    Routine = ArtFit(summary_JSON[\"BackgroundJSON\"], summary_JSON[\"pathProbe\"], summary_JSON[\"pathPump\"], summary_JSON[\"FitAvgWidth / px\"])\n",
    "    Routine.setPumpPower(summary_JSON[\"Pump power: W\"])\n",
    "    #Routine.setScale(summary_JSON[\"scale: Âµm/px\"])\n",
    "\n",
    "    Routine.plainFit(1)\n",
    "    Routine.plainFit(2)\n",
    "\n",
    "    numCorrection = Routine.getNumericCorrection(interpDensity = 32)\n",
    "    \n",
    "    return numCorrection\n",
    "\n",
    "\n",
    "\n",
    "file = open(r\"C:\\Users\\M\\Documents\\phdmatlab\\sqib-pmma-probe-wavelength\\UV_Setup\\new_parallel_pol_pump653nm\\Pump653Probe493_ArtrayCompensationControl\\TAfitPump653Probe493_OUTPUT.JSON\")\n",
    "entries = json.load(file)['entries']\n",
    "entries_files = []\n",
    "dOD = []\n",
    "for entry in entries:\n",
    "    entries_files.append(entry['inputFile'])\n",
    "    dOD.append([entry['popt'][2]+ entry['popt'][4], entry['pcov'][2][2]+entry['pcov'][4][2]])\n",
    "\n",
    "dOD = np.array(dOD)\n",
    "dOD[dOD == np.inf] = np.NaN\n",
    "\n",
    "\n",
    "\n",
    "basepath = lambda filename: r\"C:\\Users\\M\\Documents\\phdmatlab\\sqib-pmma-probe-wavelength\\UV_Setup\\new_parallel_pol_pump653nm\\Pump653Probe493_ArtrayCompensationControl\" + filename\n",
    "inputFiles = [(r\"\\SummaryPump653Probe493Caution.JSON\", r\"\\BeamFitsPump653Probe493Caution.txt\"),\n",
    "              (r\"\\SummaryPump653Probe493_ShiftedProbe.JSON\", r\"\\BeamFitsPump653Probe493_ShiftedProbe.txt\"),\n",
    "              (r\"\\SummaryPump653Probe493_WideProbe.JSON\", r\"\\BeamFitsPump653Probe493_WideProbe.txt\"),\n",
    "              (r\"\\SummaryPump653Probe493_ThinProbe.JSON\", r\"\\BeamFitsPump653Probe493_ThinProbe.txt\")]\n",
    "labels = [\"standard\", \"shifted\", \"wide probe\", \"thin probe\"]\n",
    "\n",
    "correctionFactors = []\n",
    "numericCorrectionFactors = []\n",
    "dmu = np.zeros((4,2,2))\n",
    "sigbysig = np.zeros((4,2,2))\n",
    "pump_Coeffs =[]\n",
    "probe_Coeffs = []\n",
    "\n",
    "\n",
    "\n",
    "for index, shortPath in enumerate(inputFiles):\n",
    "    tempCorrectionFactors, sigbysig[index], dmu[index], pump_temp, probe_temp, peakRad = correctionFactorWithError(basepath(shortPath[0]), basepath(shortPath[1]))\n",
    "    correctionFactors.append(tempCorrectionFactors)\n",
    "    #numericCorrectionFactors.append(getNumericCorrection(basepath(shortPath[0])))\n",
    "    print(\"xsigRatio: %.3e +- %.3e, xdmu: %.3e +- %.3e\" %(sigbysig[index, 0,0], sigbysig[index, 0,1], dmu[index, 0,0], dmu[index, 0,1]))\n",
    "    print(\"ysigRatio: %.3e +- %.3e, ydmu: %.3e +- %.3e\" %(sigbysig[index,1,0], sigbysig[index,1,1], dmu[index,1,0], dmu[index,1,1]))\n",
    "    print(\"%s: %.3e +- %.3e dOD per W/msquare\" %(labels[index], correctionFactors[index][0][0]*correctionFactors[index][0][1]*dOD[index, 0]/peakRad, correctionFactors[index][1]*dOD[index, 0]))\n",
    "    pump_Coeffs.append(pump_temp)\n",
    "    probe_Coeffs.append(probe_temp)\n",
    "#plotting\n",
    "fig, axs = plt.subplots(3,4, figsize = plotHelperLatex.figSizer(0.9,2.5), dpi = 288)\n",
    "\n",
    "#doing all 4 measurements horizontally\n",
    "def contourPlot(axis_handle, coeffs1, coeffs2, x, y, lvl = 5, colormap =\"viridis\"):\n",
    "    #x, y are x and y vectors to be used\n",
    "    \"coeffs = center, sig, Amplitude, offset\"\n",
    "    [X_contour, Y_contour] = np.meshgrid(x, y)\n",
    "    Z_contour = ArtFit.gaussian(X_contour, coeffs1)*ArtFit.gaussian(Y_contour, coeffs2)\n",
    "\n",
    "    #adjust for correct height\n",
    "    Z_contour = Z_contour/np.sqrt(coeffs1[2]*coeffs2[2])\n",
    "    axis_handle.contour(X_contour, Y_contour, Z_contour, levels = lvl, cmap = colormap)\n",
    "    axis_handle.set_aspect('equal')\n",
    "\n",
    "ticker.MaxNLocator(integer = True)\n",
    "\n",
    "def textGenerator(axis_handle, sig, dmu, correctionFactors):\n",
    "    step= -0.15*3\n",
    "    axis_handle.text(0,0, r\"x: $\\Delta \\mu$=%.1f px\" %dmu[0,0])\n",
    "    axis_handle.text(0,step, r\"$\\frac{\\sigma_{probe}}{\\sigma_{pump}}$=%.2f\" %sig[0,0])\n",
    "    axis_handle.text(0,2*step, r\"Correction: %.2f\" %correctionFactors[0])\n",
    "    axis_handle.text(0,3*step, r\"y: $\\Delta \\mu$=%.1f px\" %dmu[1,0])\n",
    "    axis_handle.text(0,4*step, r\"$\\frac{\\sigma_{probe}}{\\sigma_{pump}}$=%.2f\" %sig[1,0])\n",
    "    axis_handle.text(0,5*step, r\"Correction: %.2f\" %correctionFactors[1])\n",
    "    \n",
    "\n",
    "\n",
    "#do legend on top\n",
    "axs[0,0].text(0.5,0, \"pump pointspread\", verticalalignment =\"center\")\n",
    "axs[0,0].plot(0,0, marker = 's', color = \"purple\")\n",
    "axs[0,0].text(0.5,0.05, \"  probe pointspread\", verticalalignment =\"center\")\n",
    "axs[0,0].plot(0,0.05, marker = 's', color = \"green\")\n",
    "axs[0,0].set_xlim((-0.5,4.5))\n",
    "axs[0,0].set_ylim((-0.05,0.1))\n",
    "\n",
    "for index, shortPath in enumerate(inputFiles):\n",
    "    #fix the y inversion of the old fits\n",
    "    pump_Coeffs[index]['y'][0,0] = 300-pump_Coeffs[index]['y'][0,0]\n",
    "    probe_Coeffs[index]['y'][0,0] = 300-probe_Coeffs[index]['y'][0,0]\n",
    "\n",
    "    #remove legend axis\n",
    "    axs[0,index].set_axis_off()\n",
    "    axs[2,index].set_axis_off()\n",
    "    axs[0,index].set_adjustable('box')\n",
    "    #find x and y vectors to be used\n",
    "    x = (pump_Coeffs[index]['x'][0,0] + probe_Coeffs[index]['x'][0,0])/2\n",
    "    y = (pump_Coeffs[index]['y'][0,0] + probe_Coeffs[index]['y'][0,0])/2\n",
    "    sigMax = max([pump_Coeffs[index]['x'][1,0], pump_Coeffs[index]['y'][1,0], probe_Coeffs[index]['x'][1,0], probe_Coeffs[index]['y'][1,0]])\n",
    "    x = np.linspace(x-2*sigMax, x+2*sigMax, 100)\n",
    "    #300 for inversion since, old fit files with vertical mirror in artrayanalysis\n",
    "    y = np.linspace(y-2*sigMax, y+2*sigMax, 100)\n",
    "    \n",
    "    #plot contour pump\n",
    "    contourPlot(axs[1, index], pump_Coeffs[index]['x'][:,0], pump_Coeffs[index]['y'][:,0], x, y, colormap=\"Purples\")\n",
    "    #plot contour probe\n",
    "    contourPlot(axs[1, index], probe_Coeffs[index]['x'][:,0], probe_Coeffs[index]['y'][:,0], x, y, colormap=\"Greens\")\n",
    "    axs[1,index].tick_params(axis='both', which='major', labelsize=7)\n",
    "    axs[1,index].set_xticks([180, 185])\n",
    "    #axs[1,index].set_yticks([165, 170])\n",
    "    textGenerator(axs[2,index], sigbysig[index], dmu[index], correctionFactors[index][0])\n",
    "    #axs[2, index].text(0,0, \"test\")\n",
    "#plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "#also do the same as below\n",
    "fig2, ax2 = plt.subplots(1,4, dpi=288, figsize=plotHelperLatex.figSizer(1,4))\n",
    "\n",
    "for index, shortPath in enumerate(inputFiles):\n",
    "    #remove legend axis\n",
    "    x = (pump_Coeffs[index]['x'][0,0] + probe_Coeffs[index]['x'][0,0])/2\n",
    "    y = (pump_Coeffs[index]['y'][0,0] + probe_Coeffs[index]['y'][0,0])/2\n",
    "\n",
    "    sigMax = max([pump_Coeffs[index]['x'][1,0], pump_Coeffs[index]['y'][1,0], probe_Coeffs[index]['x'][1,0], probe_Coeffs[index]['y'][1,0]])\n",
    "    x = np.arange(x-2.5*sigMax, x+2.5*sigMax, 1, dtype=int)\n",
    "    y = np.arange(y-2.5*sigMax,y+2.5*sigMax, 1, dtype=int)\n",
    "    \n",
    "    ax2[index].tick_params(axis='both', which='major', labelsize=7)\n",
    "    #plot contour pump\n",
    "    contourPlot(ax2[index], pump_Coeffs[index]['x'][:,0], pump_Coeffs[index]['y'][:,0], x, y, colormap=\"Purples\")\n",
    "    #plot contour probe\n",
    "    contourPlot(ax2[index], probe_Coeffs[index]['x'][:,0], probe_Coeffs[index]['y'][:,0], x, y, colormap=\"Greens\")\n",
    "#plt.tight_layout()\n",
    "\n",
    "\n",
    "#no text but with legend and numeration but with legend\n",
    "fig3, ax3 = plt.subplots(3,4, figsize = plotHelperLatex.figSizer(0.9,4), dpi = 288, gridspec_kw={'height_ratios': [1, 2.5,0.5]})\n",
    "#fig3.subplots_adjust(top = 1, bottom = 0)\n",
    "y_adj = 0.1\n",
    "ax3[0,0].text(0.5,0+y_adj, \"pump pointspread\", verticalalignment =\"center\")\n",
    "ax3[0,0].plot(0,0+y_adj, marker = 's', color = \"purple\")\n",
    "ax3[0,0].text(0.5,0.5+y_adj, \"  probe pointspread\", verticalalignment =\"center\")\n",
    "ax3[0,0].plot(0,0.5+y_adj, marker = 's', color = \"green\")\n",
    "ax3[0,0].set_xlim((-0.5,4.5))\n",
    "ax3[0,0].set_ylim((-0.05,1.0))\n",
    "enumList = [\"a\", \"b\", \"c\", \"d\"]\n",
    "for index, shortPath in enumerate(inputFiles):\n",
    "    #fix the y inversion of the old fits\n",
    "    pump_Coeffs[index]['y'][0,0] = 300-pump_Coeffs[index]['y'][0,0]\n",
    "    probe_Coeffs[index]['y'][0,0] = 300-probe_Coeffs[index]['y'][0,0]\n",
    "\n",
    "    #remove legend axis\n",
    "    ax3[0,index].set_axis_off()\n",
    "    ax3[0,index].set_adjustable('box')\n",
    "    ax3[2,index].set_axis_off()\n",
    "    #find x and y vectors to be used\n",
    "    x = (pump_Coeffs[index]['x'][0,0] + probe_Coeffs[index]['x'][0,0])/2\n",
    "    y = (pump_Coeffs[index]['y'][0,0] + probe_Coeffs[index]['y'][0,0])/2\n",
    "    sigMax = max([pump_Coeffs[index]['x'][1,0], pump_Coeffs[index]['y'][1,0], probe_Coeffs[index]['x'][1,0], probe_Coeffs[index]['y'][1,0]])\n",
    "    x = np.linspace(x-2*sigMax, x+2*sigMax, 100)\n",
    "    #300 for inversion since, old fit files with vertical mirror in artrayanalysis\n",
    "    y = np.linspace(y-2*sigMax, y+2*sigMax, 100)\n",
    "\n",
    "    #text\n",
    "    ax3[2,index].text(0,0, enumList[index]+\")\",verticalalignment=\"center\")\n",
    "    \n",
    "    #plot contour pump\n",
    "    contourPlot(ax3[1, index], pump_Coeffs[index]['x'][:,0], pump_Coeffs[index]['y'][:,0], x, y, colormap=\"Purples\")\n",
    "    #plot contour probe\n",
    "    contourPlot(ax3[1, index], probe_Coeffs[index]['x'][:,0], probe_Coeffs[index]['y'][:,0], x, y, colormap=\"Greens\")\n",
    "    ax3[1,index].tick_params(axis='both', which='major', labelsize=7)\n",
    "    ax3[1,index].set_xticks([180, 185])\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(numericCorrectionFactors)\n",
    "for i in range(4):  \n",
    "    print(correctionFactors[i][0][0]*correctionFactors[i][0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np \n",
    "\n",
    "import plotHelperLatex\n",
    "plotHelperLatex.setMatplotSettings()\n",
    "\n",
    "import sys\n",
    "import json\n",
    "sys.path.insert(1, r\"C:\\Users\\M\\Documents\\phdmatlab\\sqib-pmma-probe-wavelength\\UV_Setup\\new_parallel_pol_pump653nm\")\n",
    "from peakRadianceAuto import autoPeakRadiance\n",
    "from ArtrayAnalysis import ArtFit\n",
    "#plot the graphs as contour, but not from fits\n",
    "#basing this on rerunFromJSON classmethod of ArtFit\n",
    "def countourComparisonRaw(axes_handle, JSONpath, x, y, bgSubtract = False):\n",
    "    '''currently only for full pump and probe files, implement only single beam later\n",
    "    currently always uses backgroundfile scale'''\n",
    "    print(JSONpath)\n",
    "    f_JSON = open(JSONpath, 'r')\n",
    "    summary_JSON = json.load(f_JSON)\n",
    "    f_JSON.close()\n",
    "    Routine = ArtFit(summary_JSON[\"BackgroundJSON\"], summary_JSON[\"pathProbe\"], summary_JSON[\"pathPump\"], summary_JSON[\"FitAvgWidth / px\"])\n",
    "    probeMap = Routine.probeMap - Routine.bgMap\n",
    "    pumpMap = Routine.pumpMap - Routine.bgMap\n",
    "    \n",
    "    probeMap = np.transpose(probeMap[y[0]:y[-1]+1, x[0]:x[-1]+1])\n",
    "    pumpMap = np.transpose(pumpMap[y[0]:y[-1]+1, x[0]:x[-1]+1])\n",
    "    Xgrid, Ygrid= np.meshgrid(y, x)\n",
    "    #plot probe\n",
    "    axes_handle.contour(Ygrid, Xgrid, probeMap, levels = 5, cmap = \"Greens\")\n",
    "    #plot pump\n",
    "    axes_handle.contour(Ygrid, Xgrid, pumpMap, levels = 5, cmap = \"Purples\")\n",
    "\n",
    "\n",
    "\n",
    "basepath = lambda filename: r\"C:\\Users\\M\\Documents\\phdmatlab\\sqib-pmma-probe-wavelength\\UV_Setup\\new_parallel_pol_pump653nm\\Pump653Probe493_ArtrayCompensationControl\" + filename\n",
    "inputFiles = [(r\"\\SummaryPump653Probe493Caution.JSON\", r\"\\BeamFitsPump653Probe493Caution.txt\"),\n",
    "              (r\"\\SummaryPump653Probe493_ShiftedProbe.JSON\", r\"\\BeamFitsPump653Probe493_ShiftedProbe.txt\"),\n",
    "              (r\"\\SummaryPump653Probe493_WideProbe.JSON\", r\"\\BeamFitsPump653Probe493_WideProbe.txt\"),\n",
    "              (r\"\\SummaryPump653Probe493_ThinProbe.JSON\", r\"\\BeamFitsPump653Probe493_ThinProbe.txt\")]\n",
    "\n",
    "pump_Coeffs = []\n",
    "probe_Coeffs = []\n",
    "for index, shortPath in enumerate(inputFiles):\n",
    "    dataDict = ArtFit.parseFitFile(basepath(inputFiles[index][1]))\n",
    "    pump_Coeffs.append(dataDict[\"pump\"])\n",
    "    probe_Coeffs.append(dataDict[\"probe\"])\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(3,4, figsize = plotHelperLatex.figSizer(0.9,3), dpi = 288, gridspec_kw={'height_ratios': [1, 2.5,0.5]})\n",
    "plt.subplots_adjust(wspace=0.3)\n",
    "axs[0,0].text(0.5,0, \"pump pointspread\", verticalalignment =\"center\")\n",
    "axs[0,0].plot(0,0, marker = 's', color = \"purple\")\n",
    "axs[0,0].text(0.5,0.05, \"  probe pointspread\", verticalalignment =\"center\")\n",
    "axs[0,0].plot(0,0.05, marker = 's', color = \"green\")\n",
    "axs[0,0].set_xlim((-0.5,4.5))\n",
    "axs[0,0].set_ylim((-0.05,0.1))\n",
    "\n",
    "for index, shortPath in enumerate(inputFiles):\n",
    "    #find x and y vectors to be used\n",
    "    axs[0,index].set_axis_off()\n",
    "    axs[2,index].set_axis_off()\n",
    "    axs[0,index].set_adjustable('box')\n",
    "    x = (pump_Coeffs[index]['x'][0,0] + probe_Coeffs[index]['x'][0,0])/2\n",
    "    y = (pump_Coeffs[index]['y'][0,0] + probe_Coeffs[index]['y'][0,0])/2\n",
    "    sigMax = max([pump_Coeffs[index]['x'][1,0], pump_Coeffs[index]['y'][1,0], probe_Coeffs[index]['x'][1,0], probe_Coeffs[index]['y'][1,0]])\n",
    "    x = np.arange(x-2.5*sigMax, x+2.5*sigMax, 1, dtype=int)\n",
    "    #x = np.arange(0, 300, 1)\n",
    "    y = np.arange(y-2.5*sigMax,y+2.5*sigMax, 1, dtype=int)\n",
    "    #y=np.arange(0,300,1)\n",
    "    #plot both contours\n",
    "    countourComparisonRaw(axs[1,index], basepath(inputFiles[index][0]), x, y)\n",
    "    axs[1,index].tick_params(axis='both', which='major', labelsize=7)\n",
    "    #axs[index].set_xticks([180, 185])\n",
    "    #axs[index].set_yticks([165, 170])\n",
    "    axs[2,index].text(0,0, enumList[index]+\")\",verticalalignment=\"center\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test plotting product of 4 gaussians\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def gaussian(x, popt):\n",
    "    #center, sig\n",
    "    center = popt[0]\n",
    "    sig = popt[1]\n",
    "    return 1/np.sqrt(2*np.pi)/sig*np.exp(-(center-x)**2/(2*sig**2))\n",
    "    \n",
    "#coeffs for gaussian\n",
    "\"coeffs = x_center, sig, Amplitude, offset\"\n",
    "alpha = 15/np.pi\n",
    "coeffsX_1 = [0, 10]\n",
    "coeffsX_2 = [0, 6]\n",
    "coeffsY_1 = [0, 10]\n",
    "coeffsY_2 = [0, 6]\n",
    "x = np.linspace(-30, 30, 100)\n",
    "y = np.linspace(-30, 30, 100)\n",
    "X_grid, Y_grid = np.meshgrid(x, y)\n",
    "\n",
    "Z = gaussian()\n",
    "plt.figure()\n",
    "plt.contour()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 440 vs orthogonal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from fileParsingMethods import numberFileGenerator\n",
    "import sys\n",
    "sys.path.insert(1, r\"C:\\Users\\M\\Documents\\phdmatlab\\sqib-pmma-probe-wavelength\\UV_Setup\\new_parallel_pol_pump653nm\")\n",
    "import ShowDelayScan\n",
    "\n",
    "#reference responses for 680 are identical at -1.17 mOD\n",
    "\n",
    "fileNames = numberFileGenerator(6692,6696)\n",
    "dirPath = r\"C:\\Users\\M\\Documents\\phdmatlab\\sqib-pmma-probe-wavelength\\UV_Setup\\new_parallel_pol_pump653nm\\SHG-440\\Orthogonal\"\n",
    "ShowDelayScan.fromFiles(fileNames, dirPath, showLegend= True)\n",
    "\n",
    "summaryParallel = r\"C:\\Users\\M\\Documents\\phdmatlab\\sqib-pmma-probe-wavelength\\UV_Setup\\new_parallel_pol_pump653nm\\SHG-440\\saturation_2024-01-16_19-07.mat\"\n",
    "ShowDelayScan.fromFiles(summaryParallel)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
